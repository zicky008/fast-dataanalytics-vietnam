# üîß GI·∫¢I PH√ÅP TO√ÄN DI·ªÜN: FREE AI TOOLS CHO PRODUCTION APP TESTING

**Date:** 2025-10-30  
**Purpose:** Comprehensive free AI-powered testing tools for Vietnam Data Analytics app  
**App URL:** https://fast-nicedashboard.streamlit.app/  
**Goal:** Act as real Vietnamese users, validate 5-star UX/UI with ZERO tolerance  

---

## üìã M·ª§C TI√äU TESTING

### üéØ Testing Checklist (t·ª´ user requirements):
- ‚úÖ Load time & performance c√≥ ƒë·∫°t <3s kh√¥ng?
- ‚úÖ Loading spinner c√≥ m∆∞·ª£t kh√¥ng?
- ‚úÖ Error messages c√≥ r√µ r√†ng kh√¥ng?
- ‚úÖ Vietnam context c√≥ hi·ªÉn th·ªã ƒë√∫ng kh√¥ng?
- ‚úÖ Percentile c√≥ show kh√¥ng?
- ‚úÖ Benchmark source c√≥ ƒë·∫ßy ƒë·ªß, URLs c√≥ work kh√¥ng?
- ‚úÖ Layout c√≥ ƒë·∫πp kh√¥ng?
- ‚úÖ Mobile responsive ch∆∞a?
- ‚úÖ File upload workflow c√≥ smooth kh√¥ng?
- ‚úÖ Dashboard insights c√≥ accurate kh√¥ng?
- ‚úÖ Data integrity ƒë∆∞·ª£c b·∫£o v·ªá (NEVER_IMPUTE fields)?

---

## üõ†Ô∏è CATEGORY 1: AUTOMATED STREAMLIT TESTING (Best for File Upload & Interaction)

### ‚≠ê **TOOL #1: Streamlit AppTest (Native Framework)** - HIGHLY RECOMMENDED ‚ú®

**T·∫°i sao n√™n d√πng:**
- ‚úÖ **Free & Official:** Built by Streamlit team, 100% compatible
- ‚úÖ **Headless Testing:** No browser needed, fast execution
- ‚úÖ **File Upload Support:** Can test file_uploader widget programmatically
- ‚úÖ **Widget Interaction:** Click buttons, set values, inspect outputs
- ‚úÖ **Pytest Integration:** Easy CI/CD setup
- ‚úÖ **Vietnam-Specific Testing:** Test with actual Vietnamese CSVs

**Installation:**
```bash
cd /home/user/webapp && pip install streamlit pytest
```

**Example Code - Test HR Domain with Ch·ªã Mai's Data:**
```python
"""test_streamlit_app_with_apptest.py"""
import io
from streamlit.testing.v1 import AppTest

def test_hr_data_upload_chi_mai():
    """Test as Ch·ªã Mai (HR Manager at Vinamilk) - 500 employees"""
    
    # Initialize app
    at = AppTest.from_file("streamlit_app.py").run()
    
    # Create realistic Vietnamese HR CSV
    hr_data = b"""employee_id,ho_ten,department,position,luong_thang,start_date,age,province
EMP001,Nguyen Van Anh,Technology,Senior Developer,28000000,2020-03-15,32,Ho Chi Minh
EMP002,Tran Thi Binh,Marketing,Marketing Manager,25000000,2019-06-01,35,Hanoi
EMP003,Le Van Cuong,Sales,Sales Executive,18000000,2021-08-20,28,Da Nang
EMP004,Pham Thi Dung,HR,HR Specialist,15000000,2022-01-10,26,Ho Chi Minh
EMP005,Hoang Van Ethan,Finance,Accountant,20000000,2020-11-05,30,Hanoi"""
    
    # Simulate file upload
    csv_file = io.BytesIO(hr_data)
    csv_file.name = "vinamilk_hr_data.csv"
    
    # Upload file to file_uploader widget
    at.file_uploader[0].set_value([csv_file]).run()
    
    # Wait for processing (AppTest auto-waits for reruns)
    
    # ASSERTIONS - Vietnam Context
    assert "Nh√¢n vi√™n" in at.text[0].value or "employee" in str(at.text).lower()
    assert "L∆∞∆°ng" in str(at.text) or "salary" in str(at.text).lower()
    
    # ASSERTIONS - NEVER_IMPUTE Protection
    output_text = str(at)
    assert "imputed" not in output_text.lower(), "‚ùå CRITICAL: Salary data was imputed!"
    assert "filled" not in output_text.lower(), "‚ùå CRITICAL: Protected field was filled!"
    
    # ASSERTIONS - Data Quality
    assert "Quality Score" in output_text or "ƒëi·ªÉm ch·∫•t l∆∞·ª£ng" in output_text.lower()
    
    # ASSERTIONS - Benchmark Sources
    assert "benchmark" in output_text.lower()
    assert "source" in output_text.lower() or "ngu·ªìn" in output_text.lower()
    
    print("‚úÖ PASS: Ch·ªã Mai's HR data test successful!")


def test_ecommerce_data_anh_tuan():
    """Test as Anh Tu·∫•n (E-commerce Owner) - 1000 orders/day"""
    
    at = AppTest.from_file("streamlit_app.py").run()
    
    # Vietnam E-commerce data with COD, Zalo Pay, E-wallet
    ecom_data = b"""order_id,customer_name,product,price,payment_method,province,order_date
ORD001,Nguyen Thi Mai,iPhone 15 Pro,29900000,COD,Ho Chi Minh,2024-10-01
ORD002,Tran Van Binh,Samsung Galaxy S24,22000000,Zalo Pay,Hanoi,2024-10-02
ORD003,Le Thi Cuc,AirPods Pro,5990000,E-wallet (MoMo),Da Nang,2024-10-03
ORD004,Pham Van Dung,MacBook Air M3,28990000,Bank Transfer,Ho Chi Minh,2024-10-04
ORD005,Hoang Thi Ethan,Apple Watch Ultra,19990000,COD,Can Tho,2024-10-05"""
    
    csv_file = io.BytesIO(ecom_data)
    csv_file.name = "shopee_orders.csv"
    
    at.file_uploader[0].set_value([csv_file]).run()
    
    output_text = str(at)
    
    # ASSERTIONS - Vietnam Payment Methods
    vietnam_payments = ["COD", "Zalo", "MoMo", "E-wallet"]
    has_vietnam_payment = any(payment in output_text for payment in vietnam_payments)
    assert has_vietnam_payment, "‚ùå Vietnam payment methods not recognized!"
    
    # ASSERTIONS - Vietnam Provinces
    vietnam_provinces = ["Ho Chi Minh", "Hanoi", "Da Nang", "Can Tho"]
    has_vietnam_province = any(province in output_text for province in vietnam_provinces)
    assert has_vietnam_province, "‚ùå Vietnam provinces not recognized!"
    
    # ASSERTIONS - Price Format (VND)
    assert "29900000" in output_text or "29.9" in output_text, "‚ùå Price format issue!"
    
    print("‚úÖ PASS: Anh Tu·∫•n's E-commerce test successful!")


def test_marketing_data_chi_lan():
    """Test as Ch·ªã Lan (Marketing Manager) - 100k USD/month ad spend"""
    
    at = AppTest.from_file("streamlit_app.py").run()
    
    # Vietnam Marketing data with Zalo Ads, Facebook, TikTok
    marketing_data = b"""campaign,platform,spend_usd,impressions,clicks,conversions,date
Tet_2024,Zalo Ads,5000,500000,25000,1250,2024-02-01
Summer_Sale,Facebook,8000,1000000,50000,2500,2024-06-15
Flash_Deal,TikTok,3000,750000,30000,1500,2024-08-20
Brand_Awareness,Google Ads,10000,2000000,40000,2000,2024-09-10
Influencer_Collab,Instagram,4000,600000,20000,1000,2024-10-01"""
    
    csv_file = io.BytesIO(marketing_data)
    csv_file.name = "unilever_marketing_campaigns.csv"
    
    at.file_uploader[0].set_value([csv_file]).run()
    
    output_text = str(at)
    
    # ASSERTIONS - Vietnam Platforms
    vietnam_platforms = ["Zalo", "TikTok"]
    has_vietnam_platform = any(platform in output_text for platform in vietnam_platforms)
    assert has_vietnam_platform, "‚ùå Vietnam platforms (Zalo Ads) not recognized!"
    
    # ASSERTIONS - Marketing Metrics (ROAS, CPA, CPC)
    marketing_metrics = ["ROAS", "CPA", "CPC", "CTR", "conversion"]
    has_metrics = any(metric.lower() in output_text.lower() for metric in marketing_metrics)
    assert has_metrics, "‚ùå Marketing metrics not calculated!"
    
    # ASSERTIONS - NEVER_IMPUTE Protection for spend/conversions
    assert "imputed" not in output_text.lower(), "‚ùå CRITICAL: Marketing spend imputed!"
    
    print("‚úÖ PASS: Ch·ªã Lan's Marketing test successful!")


def test_sales_data_anh_hung():
    """Test as Anh H√πng (Sales Director) - 50 sales reps, $2M quota"""
    
    at = AppTest.from_file("streamlit_app.py").run()
    
    # Vietnam Sales data
    sales_data = b"""deal_id,sales_rep,customer,deal_value,stage,close_date,province
DEAL001,Nguyen Van Sales,Vingroup,500000000,Closed Won,2024-10-01,Hanoi
DEAL002,Tran Thi Rep,FPT Corp,300000000,Negotiation,2024-10-15,Ho Chi Minh
DEAL003,Le Van Seller,VinFast,800000000,Closed Won,2024-09-20,Hai Phong
DEAL004,Pham Thi Deal,Masan Group,400000000,Proposal,2024-10-10,Ho Chi Minh
DEAL005,Hoang Van Closer,Techcombank,600000000,Closed Won,2024-09-30,Hanoi"""
    
    csv_file = io.BytesIO(sales_data)
    csv_file.name = "salesforce_deals_q4.csv"
    
    at.file_uploader[0].set_value([csv_file]).run()
    
    output_text = str(at)
    
    # ASSERTIONS - Vietnam Companies
    vietnam_companies = ["Vingroup", "FPT", "VinFast", "Masan", "Techcombank"]
    has_vietnam_company = any(company in output_text for company in vietnam_companies)
    assert has_vietnam_company, "‚ùå Vietnam companies not recognized!"
    
    # ASSERTIONS - Sales Metrics
    sales_metrics = ["win rate", "pipeline", "quota", "deal value"]
    has_metrics = any(metric.lower() in output_text.lower() for metric in sales_metrics)
    assert has_metrics, "‚ùå Sales metrics not calculated!"
    
    # ASSERTIONS - NEVER_IMPUTE Protection for deal_value
    assert "imputed" not in output_text.lower(), "‚ùå CRITICAL: Deal value imputed!"
    
    print("‚úÖ PASS: Anh H√πng's Sales test successful!")


def test_customer_service_data_chi_ngoc():
    """Test as Ch·ªã Ng·ªçc (CS Manager) - 500 tickets/day, SLA compliance"""
    
    at = AppTest.from_file("streamlit_app.py").run()
    
    # Vietnam Customer Service data
    cs_data = b"""ticket_id,customer,issue_category,priority,created_date,resolved_date,satisfaction_score,agent
TKT001,Nguyen Van Khach,Delivery Delay,High,2024-10-01 09:00,2024-10-01 11:30,4,Agent Mai
TKT002,Tran Thi User,Product Quality,Medium,2024-10-02 10:00,2024-10-02 15:00,5,Agent Binh
TKT003,Le Van Customer,Payment Issue,High,2024-10-03 08:00,2024-10-03 09:00,5,Agent Cuc
TKT004,Pham Thi Client,Account Access,Low,2024-10-04 14:00,2024-10-04 16:00,3,Agent Dung
TKT005,Hoang Van Buyer,Refund Request,Medium,2024-10-05 11:00,2024-10-05 13:30,4,Agent Ethan"""
    
    csv_file = io.BytesIO(cs_data)
    csv_file.name = "zendesk_tickets_october.csv"
    
    at.file_uploader[0].set_value([csv_file]).run()
    
    output_text = str(at)
    
    # ASSERTIONS - CS Metrics
    cs_metrics = ["resolution time", "CSAT", "SLA", "satisfaction", "response time"]
    has_metrics = any(metric.lower() in output_text.lower() for metric in cs_metrics)
    assert has_metrics, "‚ùå Customer Service metrics not calculated!"
    
    # ASSERTIONS - Vietnam Issue Categories
    vietnam_issues = ["Delivery", "Payment", "Refund"]
    has_vietnam_issue = any(issue in output_text for issue in vietnam_issues)
    assert has_vietnam_issue, "‚ùå Vietnam-specific issues not recognized!"
    
    # ASSERTIONS - NEVER_IMPUTE Protection for resolution_time, CSAT
    assert "imputed" not in output_text.lower(), "‚ùå CRITICAL: CSAT scores imputed!"
    
    print("‚úÖ PASS: Ch·ªã Ng·ªçc's Customer Service test successful!")


if __name__ == "__main__":
    """Run all 5 persona tests"""
    print("üöÄ Starting Comprehensive Vietnam Data Analytics Testing...\n")
    
    test_hr_data_upload_chi_mai()
    test_ecommerce_data_anh_tuan()
    test_marketing_data_chi_lan()
    test_sales_data_anh_hung()
    test_customer_service_data_chi_ngoc()
    
    print("\n‚úÖ ALL 5 PERSONAS PASSED! App ready for Vietnamese real users! üéâ")
```

**How to Run:**
```bash
cd /home/user/webapp && pytest test_streamlit_app_with_apptest.py -v
```

**Pros:**
- ‚úÖ Tests actual Streamlit app code
- ‚úÖ Can test file upload workflow
- ‚úÖ Fast execution (headless, no browser)
- ‚úÖ Easy to maintain (Python code)
- ‚úÖ CI/CD friendly

**Cons:**
- ‚ö†Ô∏è Cannot test visual UI rendering (no screenshots)
- ‚ö†Ô∏è Cannot test browser-specific issues
- ‚ö†Ô∏è Requires app code access (cannot test external apps directly)

**Use Case:**
- ‚úÖ **Best for:** Testing app logic, data flow, widget interactions
- ‚úÖ **Best for:** Validating Vietnam context, NEVER_IMPUTE protection
- ‚úÖ **Best for:** CI/CD automated testing

---

## üõ†Ô∏è CATEGORY 2: BROWSER AUTOMATION (For Full UI/UX Testing)

### ‚≠ê **TOOL #2: Playwright + Python** - RECOMMENDED for Production URL Testing ‚ú®

**T·∫°i sao n√™n d√πng:**
- ‚úÖ **Free & Open Source:** No licensing costs
- ‚úÖ **Modern & Fast:** 2025 industry standard, faster than Selenium
- ‚úÖ **Multi-Browser:** Chrome, Firefox, Safari (WebKit)
- ‚úÖ **File Upload Support:** Can programmatically upload files
- ‚úÖ **Screenshots & Videos:** Capture visual bugs
- ‚úÖ **Network Interception:** Monitor API calls, detect errors

**Installation:**
```bash
cd /home/user/webapp && pip install playwright pytest-playwright
cd /home/user/webapp && playwright install  # Downloads browsers
```

**Example Code - Full UX Test with File Upload:**
```python
"""test_production_with_playwright.py"""
import pytest
from playwright.sync_api import Page, expect
import time

def test_production_app_full_ux(page: Page):
    """
    Test production app as demanding Vietnamese user
    URL: https://fast-nicedashboard.streamlit.app/
    """
    
    # Navigate to production app
    page.goto("https://fast-nicedashboard.streamlit.app/", timeout=60000)
    
    # STEP 1: Measure load time
    start_time = time.time()
    page.wait_for_load_state("networkidle", timeout=60000)
    load_time = time.time() - start_time
    
    print(f"‚è±Ô∏è  Load Time: {load_time:.2f}s")
    assert load_time < 5, f"‚ùå FAIL: Load time {load_time:.2f}s > 5s target"
    
    # STEP 2: Check page title (not just "Streamlit")
    title = page.title()
    print(f"üìÑ Page Title: {title}")
    assert title != "Streamlit", "‚ùå FAIL: Page title is generic 'Streamlit'"
    
    # STEP 3: Upload CSV file
    print("üì§ Uploading Vietnamese HR CSV...")
    
    # Create temp CSV file
    csv_content = """employee_id,ho_ten,department,position,luong_thang,start_date,age
EMP001,Nguyen Van Anh,Technology,Senior Developer,28000000,2020-03-15,32
EMP002,Tran Thi Binh,Marketing,Marketing Manager,25000000,2019-06-01,35"""
    
    with open("/tmp/test_hr_vietnam.csv", "w", encoding="utf-8") as f:
        f.write(csv_content)
    
    # Locate file uploader and upload
    file_input = page.locator('input[type="file"]')
    file_input.set_input_files("/tmp/test_hr_vietnam.csv")
    
    # Wait for processing (loading spinner)
    print("‚è≥ Waiting for processing...")
    page.wait_for_selector('[data-testid="stSpinner"]', state="hidden", timeout=30000)
    
    # STEP 4: Validate Vietnam context appears
    print("üáªüá≥ Checking Vietnam context...")
    page_content = page.content()
    
    vietnam_terms = ["Nh√¢n vi√™n", "L∆∞∆°ng", "employee", "salary", "Ho Chi Minh", "Hanoi"]
    has_vietnam = any(term in page_content for term in vietnam_terms)
    assert has_vietnam, "‚ùå FAIL: No Vietnam context found in dashboard!"
    
    # STEP 5: Check for benchmark sources
    print("üìä Checking benchmark sources...")
    benchmark_keywords = ["benchmark", "source", "ngu·ªìn", "tham kh·∫£o"]
    has_benchmark = any(keyword.lower() in page_content.lower() for keyword in benchmark_keywords)
    assert has_benchmark, "‚ùå FAIL: No benchmark sources displayed!"
    
    # STEP 6: Verify no critical errors in console
    print("üîç Checking console for errors...")
    console_errors = []
    
    def handle_console(msg):
        if msg.type == "error":
            console_errors.append(msg.text)
    
    page.on("console", handle_console)
    
    # Give time for console messages
    time.sleep(2)
    
    critical_errors = [err for err in console_errors if "403" in err or "500" in err]
    assert len(critical_errors) == 0, f"‚ùå FAIL: Found critical errors: {critical_errors}"
    
    # STEP 7: Take screenshot for manual review
    page.screenshot(path="/home/user/webapp/test_production_app/dashboard_screenshot.png")
    print("üì∏ Screenshot saved!")
    
    print("‚úÖ PASS: All production UX tests passed!")


@pytest.mark.parametrize("domain,csv_file,expected_kpis", [
    ("HR", "test_hr_vietnam.csv", ["L∆∞∆°ng", "Nh√¢n vi√™n", "employee"]),
    ("E-commerce", "test_ecommerce_vietnam.csv", ["COD", "Zalo", "order"]),
    ("Marketing", "test_marketing_vietnam.csv", ["ROAS", "CPA", "campaign"]),
    ("Sales", "test_sales_vietnam.csv", ["deal", "pipeline", "win rate"]),
    ("Customer Service", "test_cs_vietnam.csv", ["CSAT", "SLA", "resolution time"]),
])
def test_all_5_domains(page: Page, domain: str, csv_file: str, expected_kpis: list):
    """Test all 5 domains with Vietnamese data"""
    
    page.goto("https://fast-nicedashboard.streamlit.app/", timeout=60000)
    
    # Upload domain-specific CSV
    file_input = page.locator('input[type="file"]')
    file_input.set_input_files(f"/home/user/webapp/test_data/{csv_file}")
    
    # Wait for processing
    page.wait_for_selector('[data-testid="stSpinner"]', state="hidden", timeout=30000)
    
    # Validate expected KPIs appear
    page_content = page.content()
    for kpi in expected_kpis:
        assert kpi.lower() in page_content.lower(), f"‚ùå FAIL: {domain} - Missing KPI '{kpi}'"
    
    print(f"‚úÖ PASS: {domain} domain test successful!")
```

**How to Run:**
```bash
cd /home/user/webapp && pytest test_production_with_playwright.py -v --headed
# Use --headed to see browser window, remove for headless
```

**Pros:**
- ‚úÖ Tests actual production URL
- ‚úÖ Can upload files and interact with UI
- ‚úÖ Screenshots and videos for visual validation
- ‚úÖ Network monitoring (detect 403 errors)
- ‚úÖ Multi-browser testing

**Cons:**
- ‚ö†Ô∏è Slower than AppTest (needs browser)
- ‚ö†Ô∏è More complex setup (browser installation)
- ‚ö†Ô∏è Requires stable internet for production URL

**Use Case:**
- ‚úÖ **Best for:** Testing production deployment
- ‚úÖ **Best for:** Visual UI/UX validation
- ‚úÖ **Best for:** End-to-end user journey testing

---

## üõ†Ô∏è CATEGORY 3: PERFORMANCE & LOAD TIME TESTING

### ‚≠ê **TOOL #3: Lighthouse CI (Free, by Google)** ‚ú®

**T·∫°i sao n√™n d√πng:**
- ‚úÖ **Free & Trusted:** Google's official tool
- ‚úÖ **Performance Score:** 0-100 scoring system
- ‚úÖ **Core Web Vitals:** LCP, FID, CLS metrics
- ‚úÖ **Automated Reports:** JSON, HTML, PDF formats
- ‚úÖ **CI/CD Integration:** Can run in GitHub Actions

**Installation:**
```bash
cd /home/user/webapp && npm install -g lighthouse
```

**Example Usage:**
```bash
# Test production app
lighthouse https://fast-nicedashboard.streamlit.app/ \
  --output=html \
  --output-path=/home/user/webapp/test_production_app/lighthouse_report.html \
  --only-categories=performance,accessibility,best-practices,seo

# Test with mobile simulation
lighthouse https://fast-nicedashboard.streamlit.app/ \
  --preset=mobile \
  --output=json \
  --output-path=/home/user/webapp/test_production_app/lighthouse_mobile.json
```

**Automated Test Script:**
```python
"""test_performance_lighthouse.py"""
import subprocess
import json

def test_lighthouse_performance():
    """Run Lighthouse and assert performance score"""
    
    # Run Lighthouse
    result = subprocess.run([
        "lighthouse",
        "https://fast-nicedashboard.streamlit.app/",
        "--output=json",
        "--output-path=/tmp/lighthouse.json",
        "--only-categories=performance",
        "--quiet"
    ], capture_output=True, text=True)
    
    # Parse results
    with open("/tmp/lighthouse.json", "r") as f:
        report = json.load(f)
    
    perf_score = report["categories"]["performance"]["score"] * 100
    metrics = report["audits"]
    
    fcp = metrics["first-contentful-paint"]["numericValue"] / 1000  # Convert to seconds
    lcp = metrics["largest-contentful-paint"]["numericValue"] / 1000
    tti = metrics["interactive"]["numericValue"] / 1000
    
    print(f"üéØ Performance Score: {perf_score}/100")
    print(f"‚è±Ô∏è  First Contentful Paint: {fcp:.2f}s")
    print(f"‚è±Ô∏è  Largest Contentful Paint: {lcp:.2f}s")
    print(f"‚è±Ô∏è  Time to Interactive: {tti:.2f}s")
    
    # ASSERTIONS
    assert perf_score >= 90, f"‚ùå FAIL: Performance score {perf_score} < 90"
    assert fcp < 1.8, f"‚ùå FAIL: FCP {fcp:.2f}s > 1.8s (Google's 'good' threshold)"
    assert lcp < 2.5, f"‚ùå FAIL: LCP {lcp:.2f}s > 2.5s (Google's 'good' threshold)"
    assert tti < 3.8, f"‚ùå FAIL: TTI {tti:.2f}s > 3.8s (Google's 'good' threshold)"
    
    print("‚úÖ PASS: Performance meets 5-star standards!")

if __name__ == "__main__":
    test_lighthouse_performance()
```

**Pros:**
- ‚úÖ Industry-standard performance metrics
- ‚úÖ Trusted by Google, used by millions
- ‚úÖ Comprehensive reports with actionable recommendations
- ‚úÖ Free forever

**Cons:**
- ‚ö†Ô∏è Cannot test file upload workflow
- ‚ö†Ô∏è Only tests initial page load

**Use Case:**
- ‚úÖ **Best for:** Performance optimization
- ‚úÖ **Best for:** Validating load time < 3s goal
- ‚úÖ **Best for:** SEO and Core Web Vitals

---

### ‚≠ê **TOOL #4: PageSpeed Insights API (Free, by Google)** ‚ú®

**T·∫°i sao n√™n d√πng:**
- ‚úÖ **Free API:** 25,000 requests/day
- ‚úÖ **Real User Data:** Chrome UX Report (CrUX)
- ‚úÖ **Lab + Field Data:** Combines Lighthouse + real users
- ‚úÖ **Automated Monitoring:** Track performance over time

**Example Python Script:**
```python
"""test_pagespeed_api.py"""
import requests
import json

def test_pagespeed_insights():
    """Test production app with PageSpeed Insights API"""
    
    api_key = "YOUR_FREE_API_KEY"  # Get from https://developers.google.com/speed/docs/insights/v5/get-started
    url = "https://fast-nicedashboard.streamlit.app/"
    
    # Call API
    api_url = f"https://www.googleapis.com/pagespeedonline/v5/runPagespeed?url={url}&key={api_key}&strategy=mobile"
    
    response = requests.get(api_url)
    data = response.json()
    
    # Parse results
    lighthouse_score = data["lighthouseResult"]["categories"]["performance"]["score"] * 100
    fcp = data["lighthouseResult"]["audits"]["first-contentful-paint"]["numericValue"] / 1000
    lcp = data["lighthouseResult"]["audits"]["largest-contentful-paint"]["numericValue"] / 1000
    
    print(f"üéØ Mobile Performance Score: {lighthouse_score}/100")
    print(f"‚è±Ô∏è  FCP: {fcp:.2f}s")
    print(f"‚è±Ô∏è  LCP: {lcp:.2f}s")
    
    # ASSERTIONS for 5-star UX
    assert lighthouse_score >= 85, f"‚ùå FAIL: Mobile performance {lighthouse_score} < 85"
    assert lcp < 3.0, f"‚ùå FAIL: Mobile LCP {lcp:.2f}s > 3.0s"
    
    # Save report
    with open("/home/user/webapp/test_production_app/pagespeed_report.json", "w") as f:
        json.dump(data, f, indent=2)
    
    print("‚úÖ PASS: Mobile performance meets standards!")

if __name__ == "__main__":
    test_pagespeed_insights()
```

**Pros:**
- ‚úÖ Free API with high quota
- ‚úÖ Real user data (not just lab)
- ‚úÖ Mobile + Desktop testing
- ‚úÖ Historical tracking

**Cons:**
- ‚ö†Ô∏è Requires API key (free to get)
- ‚ö†Ô∏è Rate limited (25k/day)

**Use Case:**
- ‚úÖ **Best for:** Continuous performance monitoring
- ‚úÖ **Best for:** Mobile responsiveness validation
- ‚úÖ **Best for:** Tracking improvements over time

---

## üõ†Ô∏è CATEGORY 4: MOBILE RESPONSIVE TESTING

### ‚≠ê **TOOL #5: BrowserStack Live (Free Tier)** ‚ú®

**T·∫°i sao n√™n d√πng:**
- ‚úÖ **Free Trial:** 100 minutes of testing
- ‚úÖ **Real Devices:** Test on actual iPhones, Android devices
- ‚úÖ **Vietnam Market:** Test on devices popular in Vietnam (Samsung, OPPO, iPhone)
- ‚úÖ **Manual Testing:** Real user interactions

**How to Use:**
1. Sign up for free trial: https://www.browserstack.com/live
2. Select device (e.g., iPhone 15 Pro, Samsung Galaxy S24)
3. Enter URL: https://fast-nicedashboard.streamlit.app/
4. Manually test:
   - Upload CSV file
   - Check if layout adapts to mobile
   - Verify charts are readable
   - Test touch interactions
5. Take screenshots and record videos

**Pros:**
- ‚úÖ Real devices (not emulators)
- ‚úÖ Test Vietnam-popular devices
- ‚úÖ No setup required (web-based)

**Cons:**
- ‚ö†Ô∏è Limited free minutes (100 minutes)
- ‚ö†Ô∏è Manual testing (not automated)

**Use Case:**
- ‚úÖ **Best for:** Mobile responsive validation
- ‚úÖ **Best for:** Device-specific testing
- ‚úÖ **Best for:** Visual QA on real devices

---

### ‚≠ê **TOOL #6: Playwright Mobile Emulation (Free, Unlimited)** ‚ú®

**T·∫°i sao n√™n d√πng:**
- ‚úÖ **Free & Unlimited:** No cost, no time limits
- ‚úÖ **Multiple Devices:** iPhone, Android emulation
- ‚úÖ **Automated:** Can script test flows
- ‚úÖ **Screenshots:** Visual validation

**Example Code:**
```python
"""test_mobile_responsive.py"""
from playwright.sync_api import sync_playwright

def test_mobile_responsive():
    """Test app on iPhone 15 Pro and Samsung Galaxy S24"""
    
    with sync_playwright() as p:
        # Test on iPhone 15 Pro
        iphone = p.devices["iPhone 15 Pro"]
        browser = p.webkit.launch()
        context = browser.new_context(**iphone)
        page = context.new_page()
        
        page.goto("https://fast-nicedashboard.streamlit.app/")
        page.wait_for_load_state("networkidle")
        
        # Check viewport width matches iPhone
        viewport = page.viewport_size
        assert viewport["width"] == 393, "‚ùå iPhone viewport not set correctly"
        
        # Check if layout is responsive
        page.screenshot(path="/home/user/webapp/test_production_app/mobile_iphone15pro.png")
        print("‚úÖ iPhone 15 Pro screenshot saved")
        
        browser.close()
        
        # Test on Samsung Galaxy S24
        galaxy = p.devices["Galaxy S24"]
        browser = p.chromium.launch()
        context = browser.new_context(**galaxy)
        page = context.new_page()
        
        page.goto("https://fast-nicedashboard.streamlit.app/")
        page.wait_for_load_state("networkidle")
        
        page.screenshot(path="/home/user/webapp/test_production_app/mobile_galaxys24.png")
        print("‚úÖ Samsung Galaxy S24 screenshot saved")
        
        browser.close()
        
    print("‚úÖ PASS: Mobile responsive testing complete!")

if __name__ == "__main__":
    test_mobile_responsive()
```

**Pros:**
- ‚úÖ Free and unlimited
- ‚úÖ Fast execution
- ‚úÖ Automated testing
- ‚úÖ CI/CD friendly

**Cons:**
- ‚ö†Ô∏è Emulation (not real devices)
- ‚ö†Ô∏è May miss device-specific issues

**Use Case:**
- ‚úÖ **Best for:** Quick mobile checks
- ‚úÖ **Best for:** CI/CD mobile testing
- ‚úÖ **Best for:** Layout validation

---

## üõ†Ô∏è CATEGORY 5: COMPREHENSIVE UX/UI FEEDBACK

### ‚≠ê **TOOL #7: AI-Powered Test Generation (Free)** ‚ú®

**Tools:**
1. **GPT-4 Vision (via API):** Analyze screenshots for UX issues
2. **Claude Code (Current Tool):** Generate test scenarios
3. **GitHub Copilot (Free for students):** Auto-generate test code

**Example - Using Claude to Generate Test Scenarios:**
```python
"""
Prompt for Claude Code:
'Generate comprehensive test scenarios for Vietnam Data Analytics app
testing with 5 personas: HR Manager, Marketing Manager, E-commerce Owner,
Sales Director, CS Manager. Include Vietnamese context validation.'
"""

# Claude will generate 50+ test scenarios automatically
```

**Pros:**
- ‚úÖ AI generates comprehensive test cases
- ‚úÖ Covers edge cases humans might miss
- ‚úÖ Fast test creation

**Cons:**
- ‚ö†Ô∏è Requires API access (may have costs)
- ‚ö†Ô∏è Generated tests need human review

**Use Case:**
- ‚úÖ **Best for:** Test case generation
- ‚úÖ **Best for:** Finding edge cases
- ‚úÖ **Best for:** Expanding test coverage

---

## üéØ RECOMMENDED TESTING STRATEGY - TO√ÄN DI·ªÜN

### **Phase 1: Automated Logic Testing (Week 1)**
```bash
# Use Streamlit AppTest for fast iteration
cd /home/user/webapp
pytest test_streamlit_app_with_apptest.py -v

# Expected: Test all 5 domains, verify Vietnam context, NEVER_IMPUTE protection
```

**Deliverables:**
- ‚úÖ 5 persona tests passing
- ‚úÖ Data integrity validated
- ‚úÖ Vietnam context confirmed

---

### **Phase 2: Production URL Testing (Week 2)**
```bash
# Use Playwright for full UX testing
cd /home/user/webapp
pytest test_production_with_playwright.py -v --headed

# Take screenshots for manual review
```

**Deliverables:**
- ‚úÖ File upload workflow tested
- ‚úÖ Dashboard rendering validated
- ‚úÖ Screenshots for visual QA

---

### **Phase 3: Performance Optimization (Week 2)**
```bash
# Use Lighthouse for performance audit
lighthouse https://fast-nicedashboard.streamlit.app/ \
  --output=html \
  --output-path=lighthouse_report.html

# Use PageSpeed Insights API for continuous monitoring
python test_pagespeed_api.py
```

**Deliverables:**
- ‚úÖ Load time < 3s achieved
- ‚úÖ Performance score ‚â• 90/100
- ‚úÖ Core Web Vitals passing

---

### **Phase 4: Mobile Responsive Testing (Week 3)**
```bash
# Use Playwright mobile emulation
python test_mobile_responsive.py

# Manual testing on BrowserStack for real devices
# Visit https://www.browserstack.com/live
```

**Deliverables:**
- ‚úÖ Mobile screenshots on iPhone, Android
- ‚úÖ Layout adapts correctly
- ‚úÖ Touch interactions work

---

### **Phase 5: Real User Testing (Week 4)**
```bash
# Recruit 5 Vietnamese users (one per domain)
# Use Google Forms for feedback collection
# Track:
# - Task completion rate
# - Time to complete
# - User satisfaction (NPS)
# - Issues encountered
```

**Deliverables:**
- ‚úÖ 5 user feedback reports
- ‚úÖ NPS score ‚â• 40 (Good)
- ‚úÖ Task completion rate ‚â• 90%

---

## üìä SUCCESS METRICS - KPI ƒê·∫†T 5 SAO

| Metric | Target | Tool | Status |
|--------|--------|------|--------|
| **Load Time** | <3s | Lighthouse | üî¥ NEED FIX (23.31s) |
| **Performance Score** | ‚â•90/100 | Lighthouse | ‚è≥ TO TEST |
| **Zero Console Errors** | 0 errors | Playwright | üî¥ NEED FIX (403) |
| **File Upload Success** | 100% | AppTest | ‚è≥ TO TEST |
| **Vietnam Context** | Present | AppTest | ‚è≥ TO TEST |
| **NEVER_IMPUTE Protection** | 131 fields | AppTest | ‚è≥ TO TEST |
| **Benchmark URLs Work** | 9/9 working | Manual | ‚úÖ VERIFIED |
| **Mobile Responsive** | Adaptive layout | Playwright | ‚è≥ TO TEST |
| **User Satisfaction** | NPS ‚â•40 | Survey | ‚è≥ TO TEST |

---

## üí° TH·ª∞C H√ÄNH NGAY - IMMEDIATE ACTION PLAN

### **Step 1: Fix Critical Issues (Today)**
```bash
# Fix load time (HIGHEST PRIORITY)
# Fix 403 error
# Set proper page title
```

### **Step 2: Run Automated Tests (Tomorrow)**
```bash
cd /home/user/webapp

# Install tools
pip install streamlit pytest playwright pytest-playwright
playwright install

# Run tests
pytest test_streamlit_app_with_apptest.py -v
pytest test_production_with_playwright.py -v
lighthouse https://fast-nicedashboard.streamlit.app/ --output=html --output-path=report.html
```

### **Step 3: Document Results (Day 3)**
```bash
# Create comprehensive test report
# Include screenshots
# Document all issues found
# Prioritize fixes
```

### **Step 4: Get Real User Feedback (Week 2-4)**
```bash
# Recruit 5 Vietnamese users
# Conduct usability testing sessions
# Collect feedback via Google Forms
# Iterate based on feedback
```

---

## üéì LEARNING RESOURCES

### Free Courses:
1. **Playwright Testing:** https://playwright.dev/docs/intro
2. **Streamlit AppTest:** https://docs.streamlit.io/develop/concepts/app-testing
3. **Lighthouse Guide:** https://developer.chrome.com/docs/lighthouse/overview
4. **PageSpeed Insights:** https://developers.google.com/speed/docs/insights/v5/get-started

### Vietnam Community:
1. **Streamlit Vietnam Group:** Facebook groups for local support
2. **Python Vietnam:** Viblo.asia articles
3. **Data Analytics Vietnam:** LinkedIn groups

---

## ‚úÖ SUMMARY - K·∫æT LU·∫¨N

### **Best Tools Combination for Vietnam Data Analytics App:**

1. **Streamlit AppTest** ‚Üí Test app logic, data integrity, Vietnam context
2. **Playwright** ‚Üí Test production URL, file upload, full UX flow
3. **Lighthouse** ‚Üí Validate performance, load time, SEO
4. **Mobile Emulation** ‚Üí Test responsive layout
5. **Real Users** ‚Üí Final validation, collect feedback

### **Cost:**
- **Total:** $0 USD (100% free tools!)
- **Time:** 2-4 weeks for comprehensive testing
- **Outcome:** Achieve 5-star UX/UI with ZERO TOLERANCE validation

### **Next Steps:**
1. ‚úÖ Use this guide to create test scripts
2. ‚úÖ Run automated tests daily
3. ‚úÖ Fix issues as they arise
4. ‚úÖ Iterate based on real user feedback
5. ‚úÖ Document everything for transparency

---

**Status:** üìã **COMPREHENSIVE SOLUTION COMPLETE**  
**Tools:** 7 free, reputable AI-powered tools  
**Coverage:** Load time, UX/UI, mobile, performance, real users  
**Cost:** $0 USD  
**Ready to implement:** ‚úÖ YES  

**Tester's Commitment:**
> *"V·ªõi b·ªô c√¥ng c·ª• n√†y, ch√∫ng ta c√≥ th·ªÉ test app nh∆∞ REAL Vietnamese users, 
> v·ªõi ZERO tolerance, v√† achieve 5-star UX/UI m·ªôt c√°ch kh√°ch quan v√† minh b·∫°ch."*
