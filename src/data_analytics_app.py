"""
DataAnalytics Vietnam - AI-Powered Data Cleaning & Dashboard Builder
·ª®ng d·ª•ng ph√¢n t√≠ch d·ªØ li·ªáu t·ª± ƒë·ªông v·ªõi Gemini AI
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import io
import base64
from datetime import datetime
from typing import Dict, List, Tuple, Any

# Import utility modules
import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))
from utils.validators import safe_file_upload, sanitize_column_names, validate_dataframe
from utils.error_handlers import rate_limit_handler, user_friendly_error
from utils.performance import log_performance, PerformanceMonitor
from google import genai
from google.genai import types
import os

# IMPORTANT: KEEP THIS COMMENT
# This uses the blueprint:python_gemini integration
# Using the new google-genai SDK (renamed from google-generativeai)
# Gemini 2.5-flash and gemini-2.5-pro are the newest models

# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="DataAnalytics Vietnam",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS t√πy ch·ªânh v·ªõi gradient xanh d∆∞∆°ng-t√≠m
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 10px;
        text-align: center;
        color: white;
        margin-bottom: 2rem;
    }
    .main-header h1 {
        font-size: 2.5rem;
        font-weight: 700;
        margin-bottom: 0.5rem;
    }
    .main-header p {
        font-size: 1.1rem;
        opacity: 0.9;
    }
    .step-card {
        background: white;
        padding: 1.5rem;
        border-radius: 10px;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        margin-bottom: 1.5rem;
        border-left: 4px solid #667eea;
    }
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1.5rem;
        border-radius: 10px;
        color: white;
        text-align: center;
    }
    .success-box {
        background: #10B981;
        color: white;
        padding: 1rem;
        border-radius: 8px;
        margin: 1rem 0;
    }
    .warning-box {
        background: #F59E0B;
        color: white;
        padding: 1rem;
        border-radius: 8px;
        margin: 1rem 0;
    }
    .info-box {
        background: #3B82F6;
        color: white;
        padding: 1rem;
        border-radius: 8px;
        margin: 1rem 0;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 2rem;
    }
    .stTabs [data-baseweb="tab"] {
        height: 50px;
        padding-left: 20px;
        padding-right: 20px;
        background-color: #f0f2f6;
        border-radius: 5px 5px 0 0;
    }
    .stTabs [aria-selected="true"] {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
    }
</style>
""", unsafe_allow_html=True)

# Header
st.markdown("""
<div class="main-header">
    <h1>üìä DataAnalytics Vietnam</h1>
    <p>Ph√¢n t√≠ch d·ªØ li·ªáu t·ª± ƒë·ªông v·ªõi AI - Data Cleaning & Dashboard Builder</p>
</div>
""", unsafe_allow_html=True)

# Initialize session state - OPTIMIZED (single dict approach)
DEFAULT_SESSION_STATE = {
    'data': None,
    'cleaned_data': None,
    'date_cols': [],
    'categorical_cols': [],
    'numerical_cols': [],
    'dataset_description': "",
    'analysis_goal': "",
    'dashboard_blueprint': None,
    'blueprint_structured_data': None,
    'eda_results': {},
    'cleaning_log': [],
    'executive_summary': None,
    'dashboard_insights': None,
    'regenerate_insights_flag': False,
    'per_chart_insights': {},
    'regenerate_chart_insights_flag': False,
    'active_filters': {},
    'dashboard_template': None
}

# Initialize all session state keys at once (more efficient)
for key, default_value in DEFAULT_SESSION_STATE.items():
    if key not in st.session_state:
        st.session_state[key] = default_value

# Kh·ªüi t·∫°o Gemini AI Client
def init_gemini():
    """Kh·ªüi t·∫°o Gemini AI"""
    api_key = os.getenv('GEMINI_API_KEY')
    if api_key:
        try:
            client = genai.Client(api_key=api_key)
            return client
        except Exception as e:
            st.error(f"‚ùå L·ªói kh·ªüi t·∫°o Gemini: {str(e)}")
            return None
    else:
        st.warning("‚ö†Ô∏è GEMINI_API_KEY ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh. M·ªôt s·ªë t√≠nh nƒÉng AI s·∫Ω kh√¥ng kh·∫£ d·ª•ng.")
        return None

# Generate AI insights v·ªõi Gemini
@rate_limit_handler(max_retries=3, backoff_base=2)
@log_performance("Gemini AI Insight Generation")
def generate_ai_insight(client, prompt: str, temperature: float = 0.7, max_tokens: int = 4096) -> Tuple[bool, str]:
    """
    T·∫°o insights t·ª´ Gemini AI v·ªõi rate limit handling v√† performance logging
    Returns: (success: bool, result: str)
    """
    try:
        response = client.models.generate_content(
            model='gemini-2.5-flash',
            contents=prompt,
            config=types.GenerateContentConfig(
                temperature=temperature,
                max_output_tokens=max_tokens,
            )
        )
        
        # Debug: Check response object
        if hasattr(response, 'text') and response.text:
            return (True, response.text)
        elif hasattr(response, 'candidates') and response.candidates:
            # Try to extract text from candidates
            if hasattr(response.candidates[0], 'content'):
                parts = response.candidates[0].content.parts
                text = ''.join([part.text for part in parts if hasattr(part, 'text')])
                if text:
                    return (True, text)
        
        # If we reach here, response has no usable content
        return (False, f"AI tr·∫£ v·ªÅ ph·∫£n h·ªìi tr·ªëng. Response object: {type(response)}. C√≥ th·ªÉ do prompt qu√° d√†i ho·∫∑c content b·ªã filter.")
    except Exception as e:
        # Use user_friendly_error() for better error messages
        return (False, user_friendly_error(e))

def parse_blueprint_structured_data(metrics_text: str, layout_text: str) -> Dict[str, Any]:
    """
    Parse OQMLB blueprint text to extract structured data for dashboard generation
    Returns: {
        'primary_kpis': [{name, priority, threshold, action_recommendations}],
        'hero_kpi': {...},  # P1 KPI
        'layout_pages': [{name, purpose, visualizations, filters}]
    }
    """
    import re
    
    result = {
        'primary_kpis': [],
        'hero_kpi': None,
        'layout_pages': []
    }
    
    # Parse PRIMARY KPIs from Metrics section
    if metrics_text:
        # Look for PRIMARY KPIs section
        primary_section_match = re.search(r'\*\*‚≠ê PRIMARY KPIs\*\*.*?(?=\n\*\*|$)', metrics_text, re.DOTALL | re.IGNORECASE)
        if primary_section_match:
            primary_text = primary_section_match.group(0)
            
            # Extract individual KPIs (looking for patterns like "**KPI Name**: ..." or numbered lists)
            kpi_blocks = re.split(r'\n\d+\.\s+\*\*|^\d+\.\s+\*\*', primary_text, flags=re.MULTILINE)
            
            for block in kpi_blocks[1:]:  # Skip first empty split
                kpi_data = {}
                
                # Extract KPI name (first bold text or after number)
                name_match = re.search(r'^\*\*(.+?)\*\*|^(.+?):\s', block)
                if name_match:
                    kpi_data['name'] = (name_match.group(1) or name_match.group(2)).strip()
                
                # Extract priority
                priority_match = re.search(r'Priority.*?[:Ôºö]\s*(\[?P[123]\]?)', block, re.IGNORECASE)
                if priority_match:
                    kpi_data['priority'] = priority_match.group(1).strip('[]')
                else:
                    kpi_data['priority'] = 'P2'  # Default
                
                # Extract threshold/target
                threshold_match = re.search(r'(?:Target|Threshold|Ng∆∞·ª°ng).*?[:Ôºö]\s*(.+?)(?:\n|$)', block, re.IGNORECASE)
                if threshold_match:
                    kpi_data['threshold'] = threshold_match.group(1).strip()
                
                # Extract action recommendations
                action_match = re.search(r'(?:Action.*?Recommendation|N√™n l√†m).*?[:Ôºö]\s*(.+?)(?=\n\*\*|$)', block, re.DOTALL | re.IGNORECASE)
                if action_match:
                    kpi_data['action_recommendations'] = action_match.group(1).strip()
                
                if kpi_data.get('name'):
                    result['primary_kpis'].append(kpi_data)
                    
                    # Set hero KPI (P1)
                    if kpi_data.get('priority') == 'P1' and not result['hero_kpi']:
                        result['hero_kpi'] = kpi_data
    
    # Parse Layout Pages
    if layout_text:
        # Find page blocks
        page_blocks = re.findall(r'\*\*Page \[?\d+\]?:?\s*(.+?)\*\*\s*(?:-\s*\*\*Purpose\*\*:?\s*(.+?))?(?=\n\*\*Page|\n##|$)', layout_text, re.DOTALL | re.IGNORECASE)
        
        for page_match in page_blocks:
            page_name = page_match[0].strip() if page_match[0] else ''
            page_purpose = page_match[1].strip() if len(page_match) > 1 and page_match[1] else ''
            
            result['layout_pages'].append({
                'name': page_name,
                'purpose': page_purpose
            })
    
    return result

def generate_dashboard_insights(client, df: pd.DataFrame, numerical_cols: list, categorical_cols: list) -> Tuple[bool, str]:
    """
    Generate AI-powered Dashboard Insights (like Bricks.ai "Overall Insights")
    Analyzes entire dashboard and returns bullet-point insights with specific numbers
    Returns: (success: bool, insights_markdown: str)
    """
    if df is None or df.empty:
        return (False, "No data available")
    
    # Calculate key statistics for numerical columns
    num_insights = []
    if numerical_cols:
        for col in numerical_cols[:5]:  # Top 5 numerical metrics
            col_mean = df[col].mean()
            col_median = df[col].median()
            col_max = df[col].max()
            col_min = df[col].min()
            col_std = df[col].std()
            col_sum = df[col].sum()
            
            num_insights.append({
                'name': col,
                'mean': col_mean,
                'median': col_median,
                'max': col_max,
                'min': col_min,
                'std': col_std,
                'sum': col_sum
            })
    
    # Calculate categorical distributions
    cat_insights = []
    if categorical_cols:
        for col in categorical_cols[:5]:  # Top 5 categorical dimensions
            value_counts = df[col].value_counts()
            top_category = value_counts.index[0] if len(value_counts) > 0 else None
            top_count = value_counts.iloc[0] if len(value_counts) > 0 else 0
            total_categories = len(value_counts)
            
            cat_insights.append({
                'name': col,
                'top_category': top_category,
                'top_count': top_count,
                'total_categories': total_categories,
                'distribution': value_counts.head(5).to_dict()
            })
    
    # Build analysis context
    num_summary = "\n".join([
        f"- **{item['name']}**: Mean={item['mean']:,.2f}, Median={item['median']:,.2f}, Max={item['max']:,.2f}, Min={item['min']:,.2f}, Sum={item['sum']:,.0f}"
        for item in num_insights
    ])
    
    cat_summary = "\n".join([
        f"- **{item['name']}**: Top={item['top_category']} ({item['top_count']} records), Total categories={item['total_categories']}"
        for item in cat_insights
    ])
    
    # Correlations (if multiple numerical columns)
    correlation_text = ""
    if len(numerical_cols) >= 2:
        corr_matrix = df[numerical_cols].corr()
        # Find top 3 correlations
        top_corrs = []
        for i in range(len(corr_matrix.columns)):
            for j in range(i+1, len(corr_matrix.columns)):
                col1 = corr_matrix.columns[i]
                col2 = corr_matrix.columns[j]
                corr_val = corr_matrix.iloc[i, j]
                if abs(corr_val) > 0.3:  # Only significant correlations
                    top_corrs.append((col1, col2, corr_val))
        
        top_corrs.sort(key=lambda x: abs(x[2]), reverse=True)
        if top_corrs:
            correlation_text = "**KEY CORRELATIONS:**\n" + "\n".join([
                f"- {c[0]} vs {c[1]}: {c[2]:.2f} correlation"
                for c in top_corrs[:3]
            ])
    
    prompt = f"""
B·∫†N L√Ä DATA ANALYST EXPERT. Ph√¢n t√≠ch dashboard data v√† t·∫°o "Overall Insights" gi·ªëng Bricks.ai format.

**DATASET OVERVIEW:**
- Total Records: {len(df):,}
- Numerical Metrics: {len(numerical_cols)}
- Categorical Dimensions: {len(categorical_cols)}

**NUMERICAL METRICS SUMMARY:**
{num_summary}

**CATEGORICAL DISTRIBUTIONS:**
{cat_summary}

{correlation_text}

---

**Y√äU C·∫¶U OUTPUT (Vietnamese):**

T·∫°o "üí° AI Dashboard Insights" theo format SAU ƒê√öNG:

### üí° AI Dashboard Insights

**üìä Key Performance Indicators:**
- [Metric name] ƒë·∫°t [specific number with unit], [comparison context, e.g., "cao h∆°n trung b√¨nh 23%"]
- [Metric name] c√≥ gi√° tr·ªã trung b√¨nh [number], [insight v·ªÅ distribution/variability]
- [Top performer insight v·ªõi specific numbers]

**üìà Trends & Patterns:**
- [Categorical dimension] c√≥ s·ª± ph√¢n b·ªë: [top category] chi·∫øm [X%], [insight]
- [Correlation insight n·∫øu c√≥, e.g., "ROI tƒÉng 1.5x khi Spend tƒÉng g·∫•p ƒë√¥i"]
- [Outlier/anomaly n·∫øu ph√°t hi·ªán ƒë∆∞·ª£c]

**üéØ Actionable Recommendations:**
- **[Priority #1]**: [Action v·ªõi specific numbers, e.g., "TƒÉng budget cho segment A t·ª´ 10M ‚Üí 15M (+50%)"]
- **[Priority #2]**: [Action]
- **[Priority #3]**: [Action]

---

**CRITICAL RULES:**
‚úÖ EVERY bullet point MUST have SPECIFIC NUMBERS (no vague statements like "performance is good")
‚úÖ Use Vietnamese business language (ROI, conversion rate, clicks, impressions, etc.)
‚úÖ Format like Bricks.ai: bullet points, concise, data-driven
‚úÖ Focus on TOP 3-5 insights per section (avoid information overload)
‚úÖ Include comparative context: percentages, comparisons, benchmarks
‚úÖ Be ACTIONABLE: recommendations must be specific and implementable
‚úÖ Limit to 8-12 bullet points total (keep it scannable)

**EXAMPLE GOOD OUTPUT (reference format):**

### üí° AI Dashboard Insights

**üìä Key Performance Indicators:**
- Total Spend ƒë·∫°t 7.86M, v·ªõi Average ROI l√† 172.99M (g·∫•p 22x chi ph√≠)
- Total Clicks ƒë·∫°t 18M l∆∞·ª£t, t·∫°o ra 57M impressions (t·ª∑ l·ªá engagement 31.5%)
- Conversion rate trung b√¨nh 0.085, v·ªõi ƒë·ªô l·ªách chu·∫©n th·∫•p (0.004) cho th·∫•y consistency t·ªët

**üìà Trends & Patterns:**
- Fashion segment chi·∫øm 50.8% total clicks (9.35M), cao h∆°n Food segment 3.4%
- Women 25-34 c√≥ conversion rate cao nh·∫•t (0.09), outperform nam gi·ªõi 12.5%
- Pinterest channel c√≥ ROI 704.57M, g·∫•p 175x c√°c channel kh√°c (Facebook: 4.03M, Twitter: 4.06M)

**üéØ Actionable Recommendations:**
- **TƒÉng budget Pinterest ngay**: Channel n√†y c√≥ ROI cao nh·∫•t nh∆∞ng spend th·∫•p nh·∫•t (1.98M), tƒÉng l√™n 4M (+100%) ƒë·ªÉ scale winning campaigns
- **Optimize targeting Women 25-34**: Segment n√†y c√≥ conversion 0.09 vs 0.08 nam gi·ªõi, n√™n shift 20-30% budget sang ƒë√¢y
- **Review Fashion campaigns**: Segment t·∫°o nhi·ªÅu clicks nh·∫•t, c·∫ßn A/B test th√™m creatives ƒë·ªÉ push conversion rate t·ª´ 0.085 ‚Üí 0.10 (+17%)

Generate insights now (Vietnamese):
"""
    
    return generate_ai_insight(client, prompt, temperature=0.4, max_tokens=4096)

def generate_per_chart_insights(client, df: pd.DataFrame, numerical_cols: list, categorical_cols: list) -> Tuple[bool, dict]:
    """
    Generate AI-powered insights for EACH chart/visual (Bricks.ai style)
    Uses 1 batched Gemini call to analyze ALL charts at once (lean cost)
    Returns: (success: bool, insights_dict: {chart_id: insights_text})
    """
    if df is None or df.empty:
        return (False, {})
    
    # Build chart definitions with data context
    chart_definitions = []
    
    # Chart 1: Trend Line Chart (first numerical column)
    if numerical_cols and len(numerical_cols) >= 1:
        col = numerical_cols[0]
        chart_definitions.append({
            'id': 'trend_chart',
            'type': 'Line Chart - Trend Analysis',
            'column': col,
            'stats': {
                'mean': df[col].mean(),
                'median': df[col].median(),
                'min': df[col].min(),
                'max': df[col].max(),
                'std': df[col].std()
            }
        })
    
    # Chart 2: Distribution Histogram (second numerical column)
    if numerical_cols and len(numerical_cols) >= 2:
        col = numerical_cols[1]
        chart_definitions.append({
            'id': 'distribution_chart',
            'type': 'Histogram - Distribution',
            'column': col,
            'stats': {
                'mean': df[col].mean(),
                'median': df[col].median(),
                'min': df[col].min(),
                'max': df[col].max(),
                'std': df[col].std()
            }
        })
    
    # Chart 3: Category Bar Chart (categorical vs numerical)
    if categorical_cols and numerical_cols:
        cat_col = categorical_cols[0]
        num_col = numerical_cols[0] if len(numerical_cols) >= 1 else numerical_cols[0]
        
        # Get top categories by numerical value
        top_cats = df.groupby(cat_col)[num_col].mean().sort_values(ascending=False).head(5)
        
        chart_definitions.append({
            'id': 'category_bar_chart',
            'type': 'Bar Chart - Category Comparison',
            'categorical_col': cat_col,
            'numerical_col': num_col,
            'top_categories': {
                str(k): float(v) for k, v in top_cats.items()
            }
        })
    
    # Chart 4: Correlation Heatmap (if 3+ numerical columns)
    if len(numerical_cols) >= 3:
        corr_matrix = df[numerical_cols[:5]].corr()
        
        # Find top correlations
        top_corrs = []
        for i in range(len(corr_matrix.columns)):
            for j in range(i+1, len(corr_matrix.columns)):
                col1 = corr_matrix.columns[i]
                col2 = corr_matrix.columns[j]
                corr_val = corr_matrix.iloc[i, j]
                if abs(corr_val) > 0.3:
                    top_corrs.append((col1, col2, corr_val))
        
        top_corrs.sort(key=lambda x: abs(x[2]), reverse=True)
        
        chart_definitions.append({
            'id': 'correlation_heatmap',
            'type': 'Heatmap - Correlation Matrix',
            'columns': numerical_cols[:5],
            'top_correlations': [
                {'col1': c[0], 'col2': c[1], 'value': float(c[2])}
                for c in top_corrs[:3]
            ]
        })
    
    # Build structured prompt for batched analysis
    charts_context = ""
    for i, chart in enumerate(chart_definitions, 1):
        charts_context += f"\n**CHART {i}: {chart['type']}**\n"
        
        if chart['id'] == 'trend_chart':
            charts_context += f"- Column: {chart['column']}\n"
            charts_context += f"- Mean: {chart['stats']['mean']:,.2f}, Median: {chart['stats']['median']:,.2f}\n"
            charts_context += f"- Range: {chart['stats']['min']:,.2f} to {chart['stats']['max']:,.2f}\n"
        
        elif chart['id'] == 'distribution_chart':
            charts_context += f"- Column: {chart['column']}\n"
            charts_context += f"- Mean: {chart['stats']['mean']:,.2f}, Std: {chart['stats']['std']:,.2f}\n"
            charts_context += f"- Range: {chart['stats']['min']:,.2f} to {chart['stats']['max']:,.2f}\n"
        
        elif chart['id'] == 'category_bar_chart':
            charts_context += f"- Categorical: {chart['categorical_col']}\n"
            charts_context += f"- Numerical: {chart['numerical_col']}\n"
            charts_context += f"- Top Categories:\n"
            for cat, val in list(chart['top_categories'].items())[:3]:
                charts_context += f"  ‚Ä¢ {cat}: {val:,.2f}\n"
        
        elif chart['id'] == 'correlation_heatmap':
            charts_context += f"- Columns: {', '.join(chart['columns'])}\n"
            charts_context += f"- Top Correlations:\n"
            for corr in chart['top_correlations']:
                charts_context += f"  ‚Ä¢ {corr['col1']} ‚Üî {corr['col2']}: {corr['value']:.2f}\n"
        
        charts_context += "\n"
    
    prompt = f"""
B·∫†N L√Ä DATA VISUALIZATION EXPERT. Ph√¢n t√≠ch t·ª´ng chart v√† t·∫°o "Key Insights" box cho M·ªñI VISUAL (Bricks.ai format).

**DATASET:** {len(df):,} records

{charts_context}

---

**Y√äU C·∫¶U OUTPUT:**

T·∫°o insights cho T·ª™NG CHART theo format SAU:

### CHART_1_INSIGHTS
‚Ä¢ [Insight #1 v·ªõi specific number, e.g., "Revenue trung b√¨nh 30 tri·ªáu VND, cao h∆°n median 15%"]
‚Ä¢ [Insight #2 v·ªÅ pattern/trend, e.g., "Peak value ƒë·∫°t 57.3 tri·ªáu, g·∫•p 1.9x trung b√¨nh"]
‚Ä¢ [Insight #3 actionable, e.g., "T·∫≠p trung v√†o top 25% performers ƒë·ªÉ t·ªëi ∆∞u ROI"]

### CHART_2_INSIGHTS
‚Ä¢ [Insight #1]
‚Ä¢ [Insight #2]
‚Ä¢ [Insight #3]

### CHART_3_INSIGHTS
‚Ä¢ [Insight #1]
‚Ä¢ [Insight #2]
‚Ä¢ [Insight #3]

### CHART_4_INSIGHTS
‚Ä¢ [Insight #1]
‚Ä¢ [Insight #2]

---

**CRITICAL RULES:**
‚úÖ M·ªói chart: 2-3 bullet points NG·∫ÆN G·ªåN (max 1 line per bullet)
‚úÖ EVERY bullet MUST have SPECIFIC NUMBERS (no vague statements)
‚úÖ Vietnamese business language (ROI, conversion, clicks, revenue, etc.)
‚úÖ Format: "### CHART_X_INSIGHTS" header + bullets
‚úÖ Actionable insights: comparisons, benchmarks, recommendations
‚úÖ Keep scannable: ƒë·ªß th√¥ng tin nh∆∞ng kh√¥ng qu√° d√†i

**EXAMPLE OUTPUT:**

### CHART_1_INSIGHTS
‚Ä¢ Total Spend trend dao ƒë·ªông 10-50 tri·ªáu VND, v·ªõi peak t·∫°i record #45 (57.3 tri·ªáu)
‚Ä¢ Spend trung b√¨nh 28.5 tri·ªáu/campaign, ·ªïn ƒë·ªãnh v·ªõi std th·∫•p (¬±8.2 tri·ªáu)
‚Ä¢ Top 20% campaigns chi·∫øm 60% total spend, c·∫ßn review allocation

### CHART_2_INSIGHTS
‚Ä¢ ROI ph√¢n b·ªë l·ªách ph·∫£i, majority (65%) trong range 100-200M
‚Ä¢ Outlier campaigns c√≥ ROI 700M+ (Pinterest channel), c·∫ßn scale
‚Ä¢ Median ROI 172M cao h∆°n mean 15%, cho th·∫•y consistency t·ªët

Generate insights cho T·ª™NG CHART now (Vietnamese, specific numbers):
"""
    
    # Call Gemini API
    success, response = generate_ai_insight(client, prompt, temperature=0.4, max_tokens=6144)
    
    if not success:
        return (False, {})
    
    # Parse response into dict {chart_id: insights}
    insights_dict = {}
    
    # Extract insights for each chart
    import re
    chart_blocks = re.findall(r'### CHART_(\d+)_INSIGHTS\s*\n((?:‚Ä¢[^\n]+\n?)+)', response, re.MULTILINE)
    
    for chart_num, insights_text in chart_blocks:
        chart_idx = int(chart_num) - 1
        if chart_idx < len(chart_definitions):
            chart_id = chart_definitions[chart_idx]['id']
            insights_dict[chart_id] = insights_text.strip()
    
    return (True, insights_dict)

def save_dashboard_template(blueprint_data: dict, analysis_goal: str, categorical_cols: list, numerical_cols: list, date_cols: list) -> str:
    """
    Save dashboard configuration as JSON template
    Returns: JSON string
    """
    import json
    from datetime import datetime
    
    template = {
        "version": "1.0",
        "created_at": datetime.now().isoformat(),
        "analysis_goal": analysis_goal,
        "column_types": {
            "categorical": categorical_cols,
            "numerical": numerical_cols,
            "date": date_cols
        },
        "blueprint": blueprint_data,
        "template_name": f"Dashboard Template - {datetime.now().strftime('%Y%m%d_%H%M%S')}"
    }
    
    return json.dumps(template, indent=2, ensure_ascii=False)

def load_dashboard_template(template_json: str) -> Tuple[bool, dict]:
    """
    Load dashboard template from JSON
    Returns: (success: bool, template_dict: dict)
    """
    import json
    
    try:
        template = json.loads(template_json)
        
        # Validate template structure
        required_keys = ["version", "analysis_goal", "column_types", "blueprint"]
        if not all(key in template for key in required_keys):
            return (False, {"error": "Invalid template format - missing required keys"})
        
        return (True, template)
    except json.JSONDecodeError as e:
        return (False, {"error": f"JSON decode error: {str(e)}"})
    except Exception as e:
        return (False, {"error": f"Template load error: {str(e)}"})

def generate_executive_summary(client, df: pd.DataFrame, blueprint: str, analysis_goal: str = "") -> Tuple[bool, str]:
    """
    Generate AI-powered Executive Summary (1-page overview)
    Returns: (success: bool, summary_markdown: str)
    """
    if df is None or df.empty:
        return (False, "No data available")
    
    # Calculate key statistics
    total_rows = len(df)
    total_cols = len(df.columns)
    
    # Get numerical column summaries
    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    num_summary = ""
    if num_cols:
        for col in num_cols[:5]:  # Top 5 numerical columns
            col_sum = df[col].sum()
            col_mean = df[col].mean()
            col_std = df[col].std()
            num_summary += f"\n- **{col}**: Total={col_sum:,.0f}, Average={col_mean:,.2f}, Std={col_std:,.2f}"
    
    # Get categorical column distributions
    cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
    cat_summary = ""
    if cat_cols:
        for col in cat_cols[:3]:  # Top 3 categorical columns
            top_vals = df[col].value_counts().head(3)
            cat_summary += f"\n- **{col}**: Top values: {', '.join([f'{k} ({v})' for k, v in top_vals.items()])}"
    
    prompt = f"""
B·∫†N L√Ä SENIOR BUSINESS ANALYST. T·∫°o EXECUTIVE SUMMARY (T√≥m t·∫Øt Qu·∫£n l√Ω) chuy√™n nghi·ªáp cho b√°o c√°o ph√¢n t√≠ch d·ªØ li·ªáu.

**DATASET OVERVIEW:**
- Rows: {total_rows:,}
- Columns: {total_cols}

**NUMERICAL METRICS:**{num_summary}

**CATEGORICAL DIMENSIONS:**{cat_summary}

**ANALYSIS GOAL:**
{analysis_goal if analysis_goal else "Ph√¢n t√≠ch t·ªïng quan v√† t√¨m insights"}

**DASHBOARD BLUEPRINT (AI-generated):**
{blueprint[:2000] if blueprint else "No blueprint available"}

---

**Y√äU C·∫¶U OUTPUT (Vietnamese):**

T·∫°o 1-page Executive Summary theo format sau (MUST HAVE SPECIFIC NUMBERS):

## üìä EXECUTIVE SUMMARY

### üéØ Overall Performance
[1-2 c√¢u t·ªïng quan v·ªÅ hi·ªáu su·∫•t t·ªïng th·ªÉ, c√≥ s·ªë li·ªáu c·ª• th·ªÉ]
- Example: "Doanh thu ƒë·∫°t 1.2M VND (+23% so v·ªõi th√°ng tr∆∞·ªõc), v∆∞·ª£t target 15%"

### ‚úÖ Top 3 Wins (ƒêi·ªÉm M·∫°nh)
1. **[Metric Name]**: [Specific number] ([% change] vs benchmark)
   - Impact: [Business impact v·ªõi s·ªë li·ªáu]
2. **[Metric Name]**: [Specific number] ([% change])
   - Impact: [Business impact]
3. **[Metric Name]**: [Specific number] ([% change])
   - Impact: [Business impact]

### ‚ö†Ô∏è Top 2 Areas of Concern (V·∫•n ƒê·ªÅ C·∫ßn Ch√∫ √ù)
1. **[Issue]**: [Current metric] ([% worse than target/benchmark])
   - Root cause: [Brief explanation]
   - Urgency: [High/Medium]
2. **[Issue]**: [Current metric] ([% deviation])
   - Root cause: [Brief explanation]
   - Urgency: [High/Medium]

### üöÄ Top 3 Recommended Actions (PRIORITY ORDER)
**[#1 - URGENT]** [Action title]
- **What**: [Specific action v·ªõi s·ªë li·ªáu, e.g., "TƒÉng budget t·ª´ 10M ‚Üí 15M VND (+50%)"]
- **Why**: [Rationale v·ªõi data evidence]
- **Expected Impact**: [Predicted outcome, e.g., "Revenue tƒÉng 16M VND trong Q4 (+25%)"]
- **Timeline**: [When to do, e.g., "Ngay trong tu·∫ßn n√†y"]

**[#2 - HIGH]** [Action title]
- **What**: [Specific action]
- **Why**: [Rationale]
- **Expected Impact**: [Predicted outcome]
- **Timeline**: [When]

**[#3 - MEDIUM]** [Action title]
- **What**: [Specific action]
- **Why**: [Rationale]
- **Expected Impact**: [Predicted outcome]
- **Timeline**: [When]

---

**CRITICAL RULES:**
‚úÖ MUST include SPECIFIC NUMBERS in every section (no vague statements)
‚úÖ Use Vietnamese business terminology
‚úÖ Be concise (1 page = ~500-600 words max)
‚úÖ Focus on ACTIONABLE insights (what decision-makers should DO)
‚úÖ Use comparative context (vs target, vs previous period, vs benchmark)
‚úÖ Prioritize by business impact (Revenue > Cost > Efficiency)

Generate the Executive Summary now:
"""
    
    return generate_ai_insight(client, prompt, temperature=0.4, max_tokens=8192)

def generate_pdf_report(df: pd.DataFrame, executive_summary: str, blueprint: str, analysis_goal: str = "") -> bytes:
    """
    Generate Professional PDF Report using ReportLab
    Returns: PDF bytes for download
    """
    from reportlab.lib.pagesizes import letter, A4
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.lib.units import inch
    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, PageBreak
    from reportlab.lib import colors
    from reportlab.lib.enums import TA_CENTER, TA_LEFT
    
    buffer = io.BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=letter, rightMargin=72, leftMargin=72, topMargin=72, bottomMargin=18)
    
    # Container for PDF elements
    story = []
    
    # Styles
    styles = getSampleStyleSheet()
    title_style = ParagraphStyle(
        'CustomTitle',
        parent=styles['Heading1'],
        fontSize=24,
        textColor=colors.HexColor('#667eea'),
        spaceAfter=30,
        alignment=TA_CENTER
    )
    heading_style = ParagraphStyle(
        'CustomHeading',
        parent=styles['Heading2'],
        fontSize=16,
        textColor=colors.HexColor('#667eea'),
        spaceAfter=12,
        spaceBefore=12
    )
    normal_style = styles['Normal']
    
    # Cover Page
    story.append(Spacer(1, 2*inch))
    story.append(Paragraph("üìä DataAnalytics Vietnam", title_style))
    story.append(Paragraph("Professional Data Analytics Report", styles['Heading3']))
    story.append(Spacer(1, 0.5*inch))
    story.append(Paragraph(f"<b>Date:</b> {datetime.now().strftime('%d/%m/%Y')}", normal_style))
    story.append(Paragraph(f"<b>Dataset:</b> {len(df)} rows √ó {len(df.columns)} columns", normal_style))
    if analysis_goal:
        story.append(Spacer(1, 0.3*inch))
        story.append(Paragraph(f"<b>Analysis Goal:</b>", normal_style))
        story.append(Paragraph(analysis_goal, normal_style))
    story.append(PageBreak())
    
    # Executive Summary
    if executive_summary:
        story.append(Paragraph("Executive Summary", title_style))
        story.append(Spacer(1, 0.2*inch))
        
        # Parse markdown to paragraphs
        for line in executive_summary.split('\n'):
            if line.strip():
                if line.startswith('##'):
                    story.append(Paragraph(line.replace('#', '').strip(), heading_style))
                elif line.startswith('###'):
                    story.append(Paragraph(line.replace('#', '').strip(), styles['Heading3']))
                else:
                    story.append(Paragraph(line, normal_style))
                story.append(Spacer(1, 6))
        
        story.append(PageBreak())
    
    # Key Metrics Table
    story.append(Paragraph("Key Performance Indicators", title_style))
    story.append(Spacer(1, 0.2*inch))
    
    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()[:6]
    if num_cols:
        kpi_data = [['Metric', 'Total', 'Average', 'Std Dev', 'Min', 'Max']]
        for col in num_cols:
            kpi_data.append([
                col,
                f"{df[col].sum():,.0f}",
                f"{df[col].mean():,.2f}",
                f"{df[col].std():,.2f}",
                f"{df[col].min():,.2f}",
                f"{df[col].max():,.2f}"
            ])
        
        kpi_table = Table(kpi_data, colWidths=[2*inch, 1*inch, 1*inch, 1*inch, 0.8*inch, 0.8*inch])
        kpi_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#667eea')),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, 0), 12),
            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
            ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
            ('GRID', (0, 0), (-1, -1), 1, colors.black)
        ]))
        story.append(kpi_table)
        story.append(PageBreak())
    
    # Dashboard Blueprint
    if blueprint:
        story.append(Paragraph("Dashboard Blueprint (OQMLB Framework)", title_style))
        story.append(Spacer(1, 0.2*inch))
        
        # Truncate blueprint to fit PDF
        blueprint_short = blueprint[:3000] + "..." if len(blueprint) > 3000 else blueprint
        for line in blueprint_short.split('\n'):
            if line.strip():
                if line.startswith('##'):
                    story.append(Paragraph(line.replace('#', '').strip(), heading_style))
                elif line.startswith('###'):
                    story.append(Paragraph(line.replace('#', '').strip(), styles['Heading3']))
                else:
                    story.append(Paragraph(line[:200], normal_style))  # Truncate long lines
                story.append(Spacer(1, 4))
    
    # Build PDF
    doc.build(story)
    buffer.seek(0)
    return buffer.getvalue()

def generate_powerpoint_report(df: pd.DataFrame, executive_summary: str, blueprint: str, analysis_goal: str = "") -> bytes:
    """
    Generate Professional PowerPoint Presentation using python-pptx
    Returns: PPTX bytes for download
    """
    from pptx import Presentation
    from pptx.util import Inches, Pt
    from pptx.enum.text import PP_ALIGN
    from pptx.dml.color import RGBColor
    
    prs = Presentation()
    prs.slide_width = Inches(10)
    prs.slide_height = Inches(7.5)
    
    # Define color scheme
    primary_color = RGBColor(102, 126, 234)  # #667eea
    accent_color = RGBColor(118, 75, 162)    # #764ba2
    
    # Slide 1: Title Slide
    title_slide_layout = prs.slide_layouts[0]
    slide = prs.slides.add_slide(title_slide_layout)
    title = slide.shapes.title
    subtitle = slide.placeholders[1]
    
    title.text = "üìä DataAnalytics Vietnam"
    subtitle.text = f"Professional Data Analytics Report\n{datetime.now().strftime('%d/%m/%Y')}"
    
    # Style title
    title.text_frame.paragraphs[0].font.size = Pt(44)
    title.text_frame.paragraphs[0].font.color.rgb = primary_color
    
    # Slide 2: Dataset Overview
    bullet_slide_layout = prs.slide_layouts[1]
    slide = prs.slides.add_slide(bullet_slide_layout)
    title = slide.shapes.title
    body = slide.placeholders[1]
    
    title.text = "üìÅ Dataset Overview"
    tf = body.text_frame
    tf.text = f"Dataset Size: {len(df):,} rows √ó {len(df.columns)} columns"
    
    if analysis_goal:
        p = tf.add_paragraph()
        p.text = f"Analysis Goal: {analysis_goal}"
        p.level = 1
    
    # Add column summary
    p = tf.add_paragraph()
    p.text = f"Numerical Columns: {len(df.select_dtypes(include=[np.number]).columns)}"
    p.level = 1
    
    p = tf.add_paragraph()
    p.text = f"Categorical Columns: {len(df.select_dtypes(include=['object', 'category']).columns)}"
    p.level = 1
    
    # Slide 3-5: Executive Summary (split into multiple slides)
    if executive_summary:
        # Parse executive summary sections
        sections = executive_summary.split('###')
        
        for i, section in enumerate(sections[1:4]):  # Take first 3 sections (Overall, Wins, Concerns)
            slide = prs.slides.add_slide(bullet_slide_layout)
            lines = section.strip().split('\n')
            
            # First line is section title
            title = slide.shapes.title
            title.text = lines[0].strip() if lines else "Executive Summary"
            
            # Rest is content
            body = slide.placeholders[1]
            tf = body.text_frame
            tf.clear()
            
            for line in lines[1:]:
                if line.strip():
                    p = tf.add_paragraph()
                    p.text = line.strip().lstrip('-').lstrip('*').strip()
                    p.font.size = Pt(14)
                    if line.strip().startswith(('1.', '2.', '3.', '**')):
                        p.level = 0
                    else:
                        p.level = 1
    
    # Slide 6: Key Metrics Table
    slide = prs.slides.add_slide(bullet_slide_layout)
    title = slide.shapes.title
    title.text = "üìä Key Performance Indicators"
    
    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()[:5]
    if num_cols:
        # Add table
        rows = len(num_cols) + 1
        cols = 4
        left = Inches(1)
        top = Inches(2)
        width = Inches(8)
        height = Inches(4)
        
        table = slide.shapes.add_table(rows, cols, left, top, width, height).table
        
        # Header row
        table.cell(0, 0).text = 'Metric'
        table.cell(0, 1).text = 'Total'
        table.cell(0, 2).text = 'Average'
        table.cell(0, 3).text = 'Std Dev'
        
        # Data rows
        for i, col in enumerate(num_cols):
            table.cell(i+1, 0).text = col
            table.cell(i+1, 1).text = f"{df[col].sum():,.0f}"
            table.cell(i+1, 2).text = f"{df[col].mean():,.2f}"
            table.cell(i+1, 3).text = f"{df[col].std():,.2f}"
    
    # Slide 7: Recommendations
    slide = prs.slides.add_slide(bullet_slide_layout)
    title = slide.shapes.title
    title.text = "üöÄ Recommended Actions"
    
    body = slide.placeholders[1]
    tf = body.text_frame
    tf.text = "Based on data analysis:"
    
    # Extract recommendations from executive summary
    if executive_summary and "Recommended Actions" in executive_summary:
        rec_section = executive_summary.split("Recommended Actions")[-1]
        rec_lines = rec_section.split('\n')[:10]  # First 10 lines
        
        for line in rec_lines:
            if line.strip() and not line.startswith('#'):
                p = tf.add_paragraph()
                p.text = line.strip().lstrip('-').lstrip('*').strip()
                p.font.size = Pt(14)
    
    # Slide 8: Thank You
    slide = prs.slides.add_slide(title_slide_layout)
    title = slide.shapes.title
    subtitle = slide.placeholders[1]
    
    title.text = "Thank You! üôè"
    subtitle.text = "DataAnalytics Vietnam\nPowered by Gemini AI"
    
    # Save to bytes
    buffer = io.BytesIO()
    prs.save(buffer)
    buffer.seek(0)
    return buffer.getvalue()

# Sidebar - Ch·ªçn workflow
st.sidebar.markdown("## üéØ Quy tr√¨nh l√†m vi·ªác")
st.sidebar.markdown("""
**OQMLB Framework:**
- **O**: Objectives (M·ª•c ti√™u)
- **Q**: Questions (C√¢u h·ªèi)
- **M**: Metrics (Ch·ªâ s·ªë)
- **L**: Layout (B·ªë c·ª•c)
- **B**: Build (X√¢y d·ª±ng)
""")

workflow_step = st.sidebar.radio(
    "Ch·ªçn b∆∞·ªõc l√†m vi·ªác:",
    ["üìÅ Step 1: Data Import & Overview", 
     "üßπ Step 2: Data Cleaning", 
     "üìä Step 3: EDA & Insights",
     "üé® Step 4: Dashboard Blueprint",
     "üöÄ Step 5: Build Dashboard"],
    index=0
)

# Main content based on workflow step
if workflow_step == "üìÅ Step 1: Data Import & Overview":
    st.markdown("""
    <div class="step-card">
        <h2>üìÅ B∆∞·ªõc 1: Data Import & Overview</h2>
        <p>Import d·ªØ li·ªáu v√† ph√¢n t√≠ch t·ªïng quan</p>
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("### üì§ Upload Dataset")
        uploaded_file = st.file_uploader(
            "Ch·ªçn file CSV ho·∫∑c Excel",
            type=['csv', 'xlsx', 'xls'],
            help="T·∫£i l√™n file d·ªØ li·ªáu c·ªßa b·∫°n"
        )
        
        if uploaded_file:
            # Use safe_file_upload() utility with comprehensive error handling
            success, df, message = safe_file_upload(
                uploaded_file,
                max_size_mb=200,
                show_progress=True
            )
            
            if success:
                st.session_state.data = df
                st.success(message)
            else:
                st.error(message)
                st.stop()
            
            try:
                
                # üöÄ PHASE 2B: SMART DATA REFRESH (Bricks.ai one-click refresh!)
                if st.session_state.blueprint_structured_data:
                    st.markdown("---")
                    
                    # Auto-detect column matching first
                    existing_cols = set(st.session_state.categorical_cols + st.session_state.numerical_cols)
                    new_cols = set(df.columns)
                    matching_cols = existing_cols.intersection(new_cols)
                    match_rate = len(matching_cols) / len(existing_cols) * 100 if existing_cols else 0
                    
                    if match_rate >= 70:
                        # HIGH MATCH RATE: Show Smart Refresh option
                        st.info("üîÑ **Smart Refresh detected!** B·∫°n ƒë√£ c√≥ dashboard blueprint. C√≥ th·ªÉ refresh data nhanh!")
                        
                        refresh_col1, refresh_col2 = st.columns([3, 2])
                        
                        with refresh_col1:
                            st.markdown("#### üöÄ Quick Dashboard Refresh")
                            st.caption("Upload data m·ªõi v·ªõi c√πng structure ‚Üí gi·ªØ nguy√™n blueprint ‚Üí skip Steps 2-4")
                            
                            st.success(f"‚úÖ Column matching: {match_rate:.0f}% ({len(matching_cols)}/{len(existing_cols)} columns)")
                            st.write(f"**Matched columns:** {', '.join(sorted(matching_cols)[:10])}{'...' if len(matching_cols) > 10 else ''}")
                            
                            if st.button("‚ö° Smart Refresh - Jump to Dashboard", type="primary", use_container_width=True):
                                # Preserve column types and blueprint
                                st.session_state.cleaned_data = df
                                st.success("üéâ Smart Refresh complete! Jumping to Step 5...")
                                st.info("üí° Blueprint v√† chart configs ƒë∆∞·ª£c gi·ªØ nguy√™n, ch·ªâ data ƒë∆∞·ª£c refresh!")
                                st.rerun()
                        
                        with refresh_col2:
                            st.markdown("#### üîÅ Rebuild Option")
                            st.caption("Ho·∫∑c rebuild dashboard t·ª´ ƒë·∫ßu")
                            if st.button("üìù Rebuild Dashboard", use_container_width=True):
                                # Clear blueprint to force full rebuild
                                st.session_state.blueprint_structured_data = None
                                st.session_state.dashboard_blueprint = None
                                st.session_state.cleaned_data = None
                                st.success("‚úÖ Cleared old blueprint - proceed with normal flow below")
                                st.rerun()
                    else:
                        # LOW MATCH RATE: Force rebuild
                        st.warning(f"‚ö†Ô∏è **Column matching th·∫•p: {match_rate:.0f}%** - Data structure kh√°c, c·∫ßn rebuild dashboard!")
                        st.write(f"**Missing columns:** {', '.join(existing_cols - new_cols)}")
                        st.write(f"**New columns:** {', '.join(new_cols - existing_cols)}")
                        
                        if st.button("üîÅ Clear Blueprint & Rebuild", type="primary", use_container_width=True):
                            # Force clear blueprint and reset workflow
                            st.session_state.blueprint_structured_data = None
                            st.session_state.dashboard_blueprint = None
                            st.session_state.cleaned_data = None
                            st.session_state.per_chart_insights = {}
                            st.session_state.dashboard_insights = None
                            st.success("‚úÖ Blueprint cleared! Proceed with Steps 2-4 below")
                            st.rerun()
                        
                        st.info("üí° Rebuild s·∫Ω cho ph√©p b·∫°n l√†m l·∫°i to√†n b·ªô Steps 2-4 v·ªõi data structure m·ªõi")
                    
                    st.markdown("---")
                
                # M√¥ t·∫£ dataset
                st.markdown("### üìù M√¥ t·∫£ Dataset")
                st.session_state.dataset_description = st.text_area(
                    "M√¥ t·∫£ dataset c·ªßa b·∫°n (lo·∫°i d·ªØ li·ªáu, ng√†nh ngh·ªÅ, v.v.):",
                    value=st.session_state.dataset_description,
                    placeholder="V√≠ d·ª•: D·ªØ li·ªáu b√°n h√†ng th√°ng 1-12/2024, bao g·ªìm th√¥ng tin kh√°ch h√†ng, s·∫£n ph·∫©m, doanh thu..."
                )
                
                st.session_state.analysis_goal = st.text_area(
                    "M·ª•c ti√™u ph√¢n t√≠ch:",
                    value=st.session_state.analysis_goal,
                    placeholder="V√≠ d·ª•: Ph√¢n t√≠ch xu h∆∞·ªõng doanh thu, t√¨m s·∫£n ph·∫©m b√°n ch·∫°y, ph√¢n kh√∫c kh√°ch h√†ng..."
                )
                
                # T·ª± ƒë·ªông ph√¢n lo·∫°i columns
                st.markdown("### üîç Ph√¢n lo·∫°i Columns")
                st.info("üìå **L∆∞u √Ω**: H√£y x√°c ƒë·ªãnh ch√≠nh x√°c lo·∫°i d·ªØ li·ªáu ƒë·ªÉ AI ph√¢n t√≠ch ƒë√∫ng!")
                
                all_cols = df.columns.tolist()
                
                # Auto-detect datetime columns
                auto_date_cols = []
                if len(df) > 0:
                    for col in df.columns:
                        if df[col].dtype == 'datetime64[ns]':
                            auto_date_cols.append(col)
                        elif df[col].dtype == 'object':
                            try:
                                pd.to_datetime(df[col], errors='coerce')
                                non_null_ratio = df[col].notna().sum() / len(df)
                                if non_null_ratio > 0.8:
                                    sample_parsed = pd.to_datetime(df[col].dropna().head(100), errors='coerce')
                                    if len(sample_parsed) > 0 and sample_parsed.notna().sum() / len(sample_parsed) > 0.7:
                                        auto_date_cols.append(col)
                            except:
                                pass
                
                # Auto-detect categorical and numerical (excluding detected dates)
                remaining_cols = [col for col in df.columns if col not in auto_date_cols]
                auto_categorical = [col for col in df.select_dtypes(include=['object', 'category']).columns if col not in auto_date_cols]
                auto_numerical = [col for col in df.select_dtypes(include=['int64', 'float64']).columns if col not in auto_date_cols]
                
                st.session_state.date_cols = st.multiselect(
                    "üìÖ Date/Time Columns (ng√†y th√°ng, th·ªùi gian):",
                    options=all_cols,
                    default=auto_date_cols
                )
                
                st.session_state.categorical_cols = st.multiselect(
                    "üìÇ Categorical Columns (ph√¢n lo·∫°i, text, ID, t√™n...):",
                    options=all_cols,
                    default=auto_categorical
                )
                
                st.session_state.numerical_cols = st.multiselect(
                    "üìä Numerical Columns (s·ªë h·ªçc, ƒë·ªÉ t√≠nh to√°n):",
                    options=all_cols,
                    default=auto_numerical
                )
                
                # Parse datetime columns
                if st.session_state.date_cols:
                    for col in st.session_state.date_cols:
                        try:
                            df[col] = pd.to_datetime(df[col], errors='coerce')
                        except:
                            st.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ parse column '{col}' th√†nh datetime")
                    st.session_state.data = df
                
                # Data overview
                if st.button("üîç Ph√¢n t√≠ch t·ªïng quan", type="primary"):
                    with st.spinner("ƒêang ph√¢n t√≠ch..."):
                        st.markdown("### üìä Data Overview")
                        
                        # Basic info
                        col_a, col_b, col_c = st.columns(3)
                        with col_a:
                            st.metric("T·ªïng s·ªë d√≤ng", f"{len(df):,}")
                        with col_b:
                            st.metric("T·ªïng s·ªë c·ªôt", len(df.columns))
                        with col_c:
                            st.metric("Missing values", df.isnull().sum().sum())
                        
                        # Data types
                        st.markdown("#### üìã Ki·ªÉu d·ªØ li·ªáu")
                        st.dataframe(pd.DataFrame({
                            'Column': df.columns,
                            'Type': df.dtypes.astype(str),
                            'Non-Null': df.count().values,
                            'Null': df.isnull().sum().values,
                            'Null %': (df.isnull().sum().values.astype(float) / len(df) * 100).round(2)
                        }), width='stretch')
                        
                        # Preview
                        st.markdown("#### üëÄ Xem tr∆∞·ªõc d·ªØ li·ªáu (5 d√≤ng ƒë·∫ßu)")
                        st.dataframe(df.head(), width='stretch')
                        
                        # Summary statistics
                        if st.session_state.numerical_cols:
                            st.markdown("#### üìà Th·ªëng k√™ m√¥ t·∫£ (Numerical)")
                            st.dataframe(df[st.session_state.numerical_cols].describe(), width='stretch')
                        
                        # AI Insights v·ªõi ISO 8000 Framework
                        client = init_gemini()
                        if client:
                            st.markdown("#### ü§ñ AI Data Quality Assessment (ISO 8000 Framework)")
                            with st.spinner("Gemini ƒëang ph√¢n t√≠ch theo chu·∫©n ISO 8000..."):
                                # ISO 8000 comprehensive prompt
                                missing_pct = (df.isnull().sum().sum() / (len(df) * len(df.columns)) * 100).round(2)
                                duplicates_count = df.duplicated().sum()
                                
                                prompt = f"""
Th·ª±c hi·ªán **DATA QUALITY ASSESSMENT** theo chu·∫©n **ISO 8000** cho dataset sau:

**DATASET CONTEXT:**
- T√™n dataset: {st.session_state.dataset_description}
- M·ª•c ti√™u ph√¢n t√≠ch: {st.session_state.analysis_goal}
- K√≠ch th∆∞·ªõc: {len(df):,} rows √ó {len(df.columns)} columns
- Date/Time columns: {st.session_state.date_cols}
- Categorical columns ({len(st.session_state.categorical_cols)}): {', '.join(st.session_state.categorical_cols[:5])}{'...' if len(st.session_state.categorical_cols) > 5 else ''}
- Numerical columns ({len(st.session_state.numerical_cols)}): {', '.join(st.session_state.numerical_cols[:5])}{'...' if len(st.session_state.numerical_cols) > 5 else ''}

**DATA QUALITY METRICS:**
- Missing values: {df.isnull().sum().sum()} cells ({missing_pct}% of total data)
- Duplicate rows: {duplicates_count} ({(duplicates_count/len(df)*100):.1f}%)
- Memory usage: {(df.memory_usage(deep=True).sum() / 1024**2):.2f} MB

**Y√äU C·∫¶U PH√ÇN T√çCH (ISO 8000 Framework):**

ƒê√°nh gi√° dataset theo **6 chi·ªÅu ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu**:

**1. ACCURACY (ƒê·ªô ch√≠nh x√°c):**
- C√≥ c·ªôt n√†o c√≥ gi√° tr·ªã kh√¥ng h·ª£p l√Ω? (tu·ªïi √¢m, ng√†y t∆∞∆°ng lai, gi√° tr·ªã outlier b·∫•t th∆∞·ªùng)
- Format c√≥ nh·∫•t qu√°n? (s·ªë ƒëi·ªán tho·∫°i, email, currency)

**2. COMPLETENESS (ƒê·∫ßy ƒë·ªß):**
- Missing values ·ªü m·ª©c n√†o? (<5% OK, 5-20% Medium, >20% Critical)
- C·ªôt n√†o thi·∫øu nhi·ªÅu data nh·∫•t? C√≥ th·ªÉ drop hay c·∫ßn impute?

**3. CONSISTENCY (Nh·∫•t qu√°n):**
- C√≥ gi√° tr·ªã tr√πng l·∫∑p hay m√¢u thu·∫´n? (VD: "USA" vs "United States")
- Format c√≥ ƒë·ªìng nh·∫•t? (date formats, text casing)

**4. TIMELINESS (K·ªãp th·ªùi):**
- Data c√≥ c√≤n relevant v·ªõi m·ª•c ti√™u ph√¢n t√≠ch?
- Time range c√≥ ph√π h·ª£p?

**5. VALIDITY (H·ª£p l·ªá):**
- Gi√° tr·ªã c√≥ n·∫±m trong range ch·∫•p nh·∫≠n ƒë∆∞·ª£c?
- Data types c√≥ ƒë√∫ng? (numerical stored as text, dates as strings)

**6. UNIQUENESS (Duy nh·∫•t):**
- C√≥ duplicate records? C·∫ßn x·ª≠ l√Ω th·∫ø n√†o?

**OUTPUT Y√äU C·∫¶U:**

## üìä T√≥m t·∫Øt Ch·∫•t l∆∞·ª£ng (Quality Score: X/100)

‚úÖ **ƒêi·ªÉm m·∫°nh** (1-3 points)
‚ö†Ô∏è **V·∫•n ƒë·ªÅ c·∫ßn l∆∞u √Ω** (3-5 issues chi ti·∫øt, ranked theo priority)
üîß **Cleaning Recommendations** (Step-by-step actions cho Step 2)

## üéØ Next Steps

**∆Øu ti√™n cao:**
1. [Action item 1]
2. [Action item 2]

**∆Øu ti√™n trung b√¨nh:**
- [Action item 3]

**G·ª£i √Ω th√™m:**
- [Nice-to-have improvements]

---

**FORMAT:** Markdown, ti·∫øng Vi·ªát, professional, c·ª• th·ªÉ, actionable. Prioritize critical issues. ƒê∆∞a ra s·ªë li·ªáu c·ª• th·ªÉ khi c√≥ th·ªÉ.
"""
                                success, insight = generate_ai_insight(client, prompt, temperature=0.3, max_tokens=8192)
                                if success:
                                    with st.expander("üìã Full ISO 8000 Assessment Report", expanded=True):
                                        st.markdown(insight)
                                else:
                                    st.error(f"‚ùå {insight}")
                        
            except Exception as e:
                st.error(f"‚ùå L·ªói ƒë·ªçc file: {str(e)}")
    
    with col2:
        st.markdown("### üí° H∆∞·ªõng d·∫´n")
        st.markdown("""
        **B∆∞·ªõc 1 gi√∫p b·∫°n:**
        - ‚úÖ Import d·ªØ li·ªáu v√†o h·ªá th·ªëng
        - ‚úÖ Hi·ªÉu c·∫•u tr√∫c dataset
        - ‚úÖ Ph√¢n lo·∫°i columns ch√≠nh x√°c
        - ‚úÖ Ph√°t hi·ªán v·∫•n ƒë·ªÅ s·ªõm
        
        **L∆∞u √Ω:**
        - Ph·∫£i m√¥ t·∫£ r√µ dataset
        - X√°c ƒë·ªãnh ƒë√∫ng categorical/numerical
        - Ki·ªÉm tra missing values
        """)
        
        if st.session_state.data is not None:
            st.markdown("### ‚úÖ Tr·∫°ng th√°i")
            st.success(f"Dataset ƒë√£ load: {len(st.session_state.data)} rows")
            st.info(f"Categorical: {len(st.session_state.categorical_cols)} c·ªôt")
            st.info(f"Numerical: {len(st.session_state.numerical_cols)} c·ªôt")

elif workflow_step == "üßπ Step 2: Data Cleaning":
    st.markdown("""
    <div class="step-card">
        <h2>üßπ B∆∞·ªõc 2: Data Cleaning</h2>
        <p>8 b∆∞·ªõc l√†m s·∫°ch d·ªØ li·ªáu chuy√™n nghi·ªáp</p>
    </div>
    """, unsafe_allow_html=True)
    
    if st.session_state.data is None:
        st.warning("‚ö†Ô∏è Vui l√≤ng ho√†n th√†nh Step 1 tr∆∞·ªõc!")
    else:
        df = st.session_state.data.copy()
        
        st.markdown("### üéØ 8 B∆∞·ªõc Data Cleaning")
        st.info("üëá M·ªü r·ªông t·ª´ng b∆∞·ªõc b√™n d∆∞·ªõi ƒë·ªÉ th·ª±c hi·ªán l√†m s·∫°ch d·ªØ li·ªáu")
        
        # Step 1: Relevance
        with st.expander("1Ô∏è‚É£ Data Relevance - Lo·∫°i b·ªè c·ªôt/d√≤ng kh√¥ng c·∫ßn thi·∫øt", expanded=False):
            cols_to_keep = st.multiselect(
                "Ch·ªçn c√°c c·ªôt c·∫ßn gi·ªØ l·∫°i:",
                options=df.columns.tolist(),
                default=df.columns.tolist()
            )
            if cols_to_keep:
                df = df[cols_to_keep]
                st.success(f"‚úÖ Gi·ªØ l·∫°i {len(cols_to_keep)} c·ªôt")
                st.session_state.cleaning_log.append(f"Relevance: Gi·ªØ {len(cols_to_keep)}/{len(st.session_state.data.columns)} c·ªôt")
        
        # Step 2: Duplicates
        with st.expander("2Ô∏è‚É£ Remove Duplicates - X√≥a d·ªØ li·ªáu tr√πng l·∫∑p", expanded=False):
            dup_count = df.duplicated().sum()
            if dup_count > 0:
                st.warning(f"‚ö†Ô∏è Ph√°t hi·ªán {dup_count} d√≤ng tr√πng l·∫∑p")
                if st.button("X√≥a duplicates"):
                    df = df.drop_duplicates()
                    st.success(f"‚úÖ ƒê√£ x√≥a {dup_count} d√≤ng")
                    st.session_state.cleaning_log.append(f"Duplicates: X√≥a {dup_count} d√≤ng tr√πng")
            else:
                st.success("‚úÖ Kh√¥ng c√≥ d·ªØ li·ªáu tr√πng l·∫∑p")
        
        # Step 3: Convention
        with st.expander("3Ô∏è‚É£ Convention - Ki·ªÉm tra ch√≠nh t·∫£, ng·ªØ ph√°p", expanded=False):
            st.info("üîç Ki·ªÉm tra gi√° tr·ªã unique trong c√°c categorical columns")
            
            for col in st.session_state.categorical_cols:
                if col in df.columns:
                    unique_vals = df[col].value_counts()
                    st.markdown(f"**{col}**: {len(unique_vals)} gi√° tr·ªã unique")
                    st.dataframe(unique_vals.head(10), width='stretch')
        
        # Step 4: Format
        with st.expander("4Ô∏è‚É£ Format - Chuy·ªÉn ƒë·ªïi ki·ªÉu d·ªØ li·ªáu", expanded=False):
            
            # Convert categorical
            for col in st.session_state.categorical_cols:
                if col in df.columns:
                    df[col] = df[col].astype('category')
            
            # Convert numerical
            for col in st.session_state.numerical_cols:
                if col in df.columns:
                    try:
                        df[col] = pd.to_numeric(df[col], errors='coerce')
                    except:
                        st.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ convert {col} sang s·ªë")
            
            st.success("‚úÖ ƒê√£ chu·∫©n h√≥a ki·ªÉu d·ªØ li·ªáu")
            st.dataframe(df.dtypes, width='stretch')
        
        # Step 5: Missing Values
        with st.expander("5Ô∏è‚É£ Missing Values - X·ª≠ l√Ω gi√° tr·ªã thi·∫øu", expanded=False):
            
            missing = df.isnull().sum()
            missing_pct = (missing.astype(float) / len(df) * 100).round(2)
            missing_df = pd.DataFrame({
                'Column': missing.index,
                'Missing': missing.values,
                'Percent': missing_pct.values
            })
            missing_df = missing_df[missing_df['Missing'] > 0]
            
            if len(missing_df) > 0:
                st.warning(f"‚ö†Ô∏è Ph√°t hi·ªán {len(missing_df)} c·ªôt c√≥ missing values")
                st.dataframe(missing_df, width='stretch')
                
                st.markdown("**Ph∆∞∆°ng ph√°p x·ª≠ l√Ω:**")
                for col in missing_df['Column']:
                    method = st.selectbox(
                        f"X·ª≠ l√Ω {col}:",
                        ["Gi·ªØ nguy√™n", "X√≥a d√≤ng", "Fill mean", "Fill median", "Fill mode", "Fill 0"],
                        key=f"missing_{col}"
                    )
                    
                    if method == "X√≥a d√≤ng":
                        df = df.dropna(subset=[col])
                    elif method == "Fill mean" and col in st.session_state.numerical_cols:
                        df[col].fillna(df[col].mean(), inplace=True)
                    elif method == "Fill median" and col in st.session_state.numerical_cols:
                        df[col].fillna(df[col].median(), inplace=True)
                    elif method == "Fill mode":
                        df[col].fillna(df[col].mode()[0], inplace=True)
                    elif method == "Fill 0":
                        df[col].fillna(0, inplace=True)
                
                if st.button("‚úÖ √Åp d·ª•ng x·ª≠ l√Ω missing values"):
                    st.success("ƒê√£ x·ª≠ l√Ω missing values")
                    st.session_state.cleaning_log.append("Missing values: ƒê√£ x·ª≠ l√Ω")
            else:
                st.success("‚úÖ Kh√¥ng c√≥ missing values")
        
        # Step 6: Outliers
        with st.expander("6Ô∏è‚É£ Outliers - Ph√°t hi·ªán gi√° tr·ªã ngo·∫°i lai", expanded=False):
            
            if st.session_state.numerical_cols:
                for col in st.session_state.numerical_cols:
                    if col in df.columns:
                        # IQR method
                        Q1 = df[col].quantile(0.25)
                        Q3 = df[col].quantile(0.75)
                        IQR = Q3 - Q1
                        lower = Q1 - 1.5 * IQR
                        upper = Q3 + 1.5 * IQR
                        
                        outliers = df[(df[col] < lower) | (df[col] > upper)]
                        
                        if len(outliers) > 0:
                            st.warning(f"‚ö†Ô∏è **{col}**: {len(outliers)} outliers")
                            
                            # Boxplot
                            fig = px.box(df, y=col, title=f"Boxplot - {col}")
                            st.plotly_chart(fig, use_container_width=True)
                            
                            # Outlier treatment
                            action = st.selectbox(
                                f"X·ª≠ l√Ω outliers {col}:",
                                ["Gi·ªØ nguy√™n", "X√≥a outliers", "Cap outliers", "Transform log"],
                                key=f"outlier_{col}"
                            )
                            
                            if action == "X√≥a outliers":
                                df = df[(df[col] >= lower) & (df[col] <= upper)]
                            elif action == "Cap outliers":
                                df[col] = df[col].clip(lower, upper)
                            elif action == "Transform log":
                                df[col] = np.log1p(df[col])
        
        # Step 7: Scaling
        with st.expander("7Ô∏è‚É£ Scaling - Chu·∫©n h√≥a d·ªØ li·ªáu s·ªë", expanded=False):
            
            if st.session_state.numerical_cols:
                st.info("üìä Scaling gi√∫p ƒë∆∞a c√°c c·ªôt s·ªë v·ªÅ c√πng m·ªôt thang ƒëo, quan tr·ªçng cho Machine Learning")
                
                scaling_method = st.selectbox(
                    "Ch·ªçn ph∆∞∆°ng ph√°p scaling:",
                    ["Kh√¥ng scaling", "StandardScaler (z-score)", "MinMaxScaler (0-1)", "RobustScaler (IQR)"]
                )
                
                if scaling_method != "Kh√¥ng scaling":
                    cols_to_scale = st.multiselect(
                        "Ch·ªçn columns c·∫ßn scaling:",
                        st.session_state.numerical_cols,
                        default=st.session_state.numerical_cols
                    )
                    
                    if st.button("‚úÖ √Åp d·ª•ng scaling"):
                        from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler
                        
                        if scaling_method == "StandardScaler (z-score)":
                            scaler = StandardScaler()
                        elif scaling_method == "MinMaxScaler (0-1)":
                            scaler = MinMaxScaler()
                        else:  # RobustScaler
                            scaler = RobustScaler()
                        
                        for col in cols_to_scale:
                            if col in df.columns:
                                df[col] = scaler.fit_transform(df[[col]])
                        
                        st.success(f"‚úÖ ƒê√£ scaling {len(cols_to_scale)} columns v·ªõi {scaling_method}")
                        st.session_state.cleaning_log.append(f"Scaling: {scaling_method} cho {len(cols_to_scale)} c·ªôt")
                        
                        # Show before/after comparison
                        st.markdown("**Tr∆∞·ªõc v√† sau scaling:**")
                        for col in cols_to_scale[:3]:  # Show first 3
                            if col in df.columns:
                                col1, col2 = st.columns(2)
                                with col1:
                                    st.metric(f"{col} - Min", f"{st.session_state.data[col].min():.2f}")
                                    st.metric(f"{col} - Max", f"{st.session_state.data[col].max():.2f}")
                                with col2:
                                    st.metric(f"{col} - Min (scaled)", f"{df[col].min():.2f}")
                                    st.metric(f"{col} - Max (scaled)", f"{df[col].max():.2f}")
            else:
                st.info("Kh√¥ng c√≥ numerical columns ƒë·ªÉ scaling")
        
        # Step 8: Validation
        with st.expander("8Ô∏è‚É£ Validation - Ki·ªÉm tra k·∫øt qu·∫£ cleaning", expanded=True):
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("**Before Cleaning:**")
                st.metric("Rows", len(st.session_state.data))
                st.metric("Columns", len(st.session_state.data.columns))
                st.metric("Missing", st.session_state.data.isnull().sum().sum())
            
            with col2:
                st.markdown("**After Cleaning:**")
                st.metric("Rows", len(df), delta=len(df) - len(st.session_state.data))
                st.metric("Columns", len(df.columns), delta=len(df.columns) - len(st.session_state.data.columns))
                st.metric("Missing", df.isnull().sum().sum(), delta=df.isnull().sum().sum() - st.session_state.data.isnull().sum().sum())
            
            # Cleaning log
            st.markdown("**üìã Cleaning Log:**")
            for log in st.session_state.cleaning_log:
                st.text(f"‚úì {log}")
            
            if st.button("üíæ L∆∞u cleaned data", type="primary"):
                # Convert categorical columns to object to avoid PyArrow serialization errors
                df_to_save = df.copy()
                for col in df_to_save.select_dtypes(include=['category']).columns:
                    df_to_save[col] = df_to_save[col].astype(str)
                
                st.session_state.cleaned_data = df_to_save
                st.success("‚úÖ ƒê√£ l∆∞u cleaned data! Chuy·ªÉn sang Step 3 ƒë·ªÉ ph√¢n t√≠ch EDA.")

elif workflow_step == "üìä Step 3: EDA & Insights":
    st.markdown("""
    <div class="step-card">
        <h2>üìä B∆∞·ªõc 3: EDA & Insights</h2>
        <p>Kh√°m ph√° d·ªØ li·ªáu v√† t·∫°o insights v·ªõi AI</p>
    </div>
    """, unsafe_allow_html=True)
    
    if st.session_state.cleaned_data is None:
        st.warning("‚ö†Ô∏è Vui l√≤ng ho√†n th√†nh Step 2 tr∆∞·ªõc!")
    else:
        df = st.session_state.cleaned_data.copy()
        
        eda_tabs = st.tabs([
            "üìà Univariate", 
            "üîó Bivariate",
            "üéØ Multivariate",
            "ü§ñ AI Insights"
        ])
        
        with eda_tabs[0]:  # Univariate
            st.markdown("### üìà Ph√¢n t√≠ch ƒë∆°n bi·∫øn (Univariate)")
            
            # Numerical distributions
            if st.session_state.numerical_cols:
                st.markdown("#### Ph√¢n ph·ªëi Numerical Columns")
                for col in st.session_state.numerical_cols:
                    if col in df.columns:
                        fig = px.histogram(df, x=col, title=f"Distribution: {col}", 
                                         marginal="box", nbins=30)
                        st.plotly_chart(fig, use_container_width=True)
            
            # Categorical frequencies
            if st.session_state.categorical_cols:
                st.markdown("#### T·∫ßn su·∫•t Categorical Columns")
                for col in st.session_state.categorical_cols:
                    if col in df.columns:
                        value_counts = df[col].value_counts().head(10)
                        fig = px.bar(x=value_counts.index, y=value_counts.values,
                                   title=f"Frequency: {col}",
                                   labels={'x': col, 'y': 'Count'})
                        st.plotly_chart(fig, use_container_width=True)
            
            # DateTime time series
            if st.session_state.get('date_cols', []):
                st.markdown("#### Ph√¢n t√≠ch Time Series")
                for date_col in st.session_state.get('date_cols', []):
                    if date_col in df.columns and pd.api.types.is_datetime64_any_dtype(df[date_col]):
                        df_sorted = df.sort_values(date_col)
                        fig = px.line(df_sorted, x=date_col, y=df_sorted.index,
                                    title=f"Timeline: {date_col}")
                        st.plotly_chart(fig, use_container_width=True)
        
        with eda_tabs[1]:  # Bivariate
            st.markdown("### üîó Ph√¢n t√≠ch song bi·∫øn (Bivariate)")
            
            # Correlation heatmap
            if len(st.session_state.numerical_cols) >= 2:
                numerical_data = df[st.session_state.numerical_cols].select_dtypes(include=[np.number])
                corr = numerical_data.corr()
                
                fig = px.imshow(corr, 
                              text_auto=True,
                              title="Correlation Heatmap",
                              color_continuous_scale="RdBu_r")
                st.plotly_chart(fig, use_container_width=True)
            
            # Scatter plots
            if len(st.session_state.numerical_cols) >= 2:
                st.markdown("#### Scatter Plots")
                col_x = st.selectbox("Ch·ªçn X axis:", st.session_state.numerical_cols)
                col_y = st.selectbox("Ch·ªçn Y axis:", 
                                   [c for c in st.session_state.numerical_cols if c != col_x])
                
                fig = px.scatter(df, x=col_x, y=col_y, title=f"{col_x} vs {col_y}",
                               trendline="ols")
                st.plotly_chart(fig, use_container_width=True)
            
            # Time series with numerical values
            if st.session_state.get('date_cols', []) and st.session_state.numerical_cols:
                st.markdown("#### Time Series Analysis")
                date_col = st.selectbox("Ch·ªçn Date column:", st.session_state.get('date_cols', []))
                num_col = st.selectbox("Ch·ªçn Numerical column:", st.session_state.numerical_cols)
                
                if date_col in df.columns and num_col in df.columns:
                    df_sorted = df[[date_col, num_col]].dropna().sort_values(date_col)
                    fig = px.line(df_sorted, x=date_col, y=num_col,
                                title=f"{num_col} theo th·ªùi gian")
                    st.plotly_chart(fig, use_container_width=True)
        
        with eda_tabs[2]:  # Multivariate
            st.markdown("### üéØ Ph√¢n t√≠ch ƒëa bi·∫øn (Multivariate)")
            
            # Pairplot-style
            if len(st.session_state.numerical_cols) >= 2:
                selected_cols = st.multiselect(
                    "Ch·ªçn columns ƒë·ªÉ ph√¢n t√≠ch:",
                    st.session_state.numerical_cols,
                    default=st.session_state.numerical_cols[:min(3, len(st.session_state.numerical_cols))]
                )
                
                if len(selected_cols) >= 2:
                    fig = px.scatter_matrix(df[selected_cols],
                                          title="Scatter Matrix")
                    st.plotly_chart(fig, use_container_width=True)
        
        with eda_tabs[3]:  # AI Insights
            st.markdown("### ü§ñ AI-Powered Insights")
            
            client = init_gemini()
            if client:
                if st.button("üöÄ T·∫°o AI Insights", type="primary"):
                    with st.spinner("Gemini ƒëang ph√¢n t√≠ch d·ªØ li·ªáu..."):
                        # Prepare data summary
                        summary = f"""
Dataset: {st.session_state.dataset_description}
M·ª•c ti√™u: {st.session_state.analysis_goal}

Th√¥ng tin d·ªØ li·ªáu sau cleaning:
- Rows: {len(df)}
- Columns: {len(df.columns)}
- Date/Time: {st.session_state.date_cols}
- Categorical: {st.session_state.categorical_cols}
- Numerical: {st.session_state.numerical_cols}

Th·ªëng k√™ m√¥ t·∫£:
{df[st.session_state.numerical_cols].describe().to_string() if st.session_state.numerical_cols else 'N/A'}

D·ªØ li·ªáu m·∫´u:
{df.head(5).to_string()}
"""
                        
                        prompt = f"""
Th·ª±c hi·ªán **EXPLORATORY DATA ANALYSIS & DATA TRANSFORMATION** theo best practices AWS/Google/Microsoft cho dataset:

{summary}

**Y√äU C·∫¶U PH√ÇN T√çCH (ETL Standards - AWS/Google/Microsoft):**

## üìä PART 1: KEY FINDINGS & PATTERNS

**1.1 Statistical Insights:**
- Ph√¢n ph·ªëi numerical columns: Normal? Skewed? C√≥ outliers?
- Top insights t·ª´ correlation matrix (n·∫øu c√≥)
- Xu h∆∞·ªõng th·ªùi gian (time-series patterns n·∫øu c√≥ date columns)

**1.2 Data Patterns:**
- Categorical distributions: C·ªôt n√†o unbalanced? C√≥ missing categories?
- Relationships: Correlations m·∫°nh nh·∫•t? Dependencies gi·ªØa columns?
- Anomalies: Outliers, unusual patterns, data quality issues c√≤n s√≥t

## üîß PART 2: DATA TRANSFORMATION RECOMMENDATIONS (ETL Best Practices)

**2.1 Feature Engineering Suggestions:**
- **Time-based features** (n·∫øu c√≥ date): year, month, quarter, day_of_week, is_weekend, days_since_X
- **Derived metrics**: T√≠nh to√°n KPIs t·ª´ raw data (VD: total_revenue = price √ó quantity, profit_margin)
- **Categorical encoding**: One-hot? Label? Target encoding? (recommend cho t·ª´ng column)
- **Binning**: Age groups, revenue ranges theo business logic

**2.2 Aggregation Strategies:**
- **Time-series aggregation**: Daily/Weekly/Monthly summaries
- **Categorical aggregation**: Group by product/region/segment
- **KPIs calculation**: Common metrics cho domain n√†y (Sales: AOV, Conversion Rate; Marketing: ROAS, CTR, CPA)

**2.3 Visualization-Ready Datasets:**
- Recommend c·∫•u tr√∫c data cho t·ª´ng chart type:
  - Line charts: [Date, Metric1, Metric2]
  - Bar charts: [Category, Value, Percentage]
  - Heatmaps: Correlation matrix pre-computed

## üí° PART 3: BUSINESS RECOMMENDATIONS

**3.1 Actionable Insights:**
- Top 3-5 ph√°t hi·ªán quan tr·ªçng nh·∫•t cho business
- C∆° h·ªôi: Trends t·ªët ƒë·ªÉ capitalize
- Risks: V·∫•n ƒë·ªÅ c·∫ßn gi·∫£i quy·∫øt ngay

**3.2 Dashboard Readiness:**
- Data ƒë√£ s·∫µn s√†ng cho dashboard ch∆∞a?
- C·∫ßn transform/aggregate th√™m g√¨?
- Recommend primary KPIs cho dashboard

## üéØ PART 4: NEXT STEPS

**∆Øu ti√™n cao:**
1. Feature engineering steps c·ª• th·ªÉ
2. KPIs c·∫ßn calculate
3. Data transformations c·∫ßn thi·∫øt

**∆Øu ti√™n trung b√¨nh:**
- Deeper analysis opportunities
- A/B testing ideas (n·∫øu applicable)

---

**OUTPUT FORMAT:**
- Markdown professional, d·ªÖ ƒë·ªçc
- Ti·∫øng Vi·ªát
- C√≥ s·ªë li·ªáu c·ª• th·ªÉ (kh√¥ng chung chung)
- Actionable recommendations (KH√îNG ph·∫£i "n√™n xem x√©t", ph·∫£i c·ª• th·ªÉ "C·∫ßn t√≠nh metric X = formula Y")

**DATA TRANSFORMATION PRINCIPLES:**
- Apply AWS/Google/Microsoft ETL best practices
- Prepare data for scalable dashboard
- Optimize for performance (<5MB datasets, pre-aggregated KPIs)
"""
                        success, insight = generate_ai_insight(client, prompt, temperature=0.5, max_tokens=8192)
                        if success:
                            st.session_state.eda_results['ai_insights'] = insight
                            with st.expander("üìã Full EDA & Transformation Report", expanded=True):
                                st.markdown(insight)
                        else:
                            st.error(f"‚ùå {insight}")
                            st.warning("üí° Vui l√≤ng ki·ªÉm tra GEMINI_API_KEY ho·∫∑c th·ª≠ l·∫°i sau.")
            else:
                st.info("üí° C·∫ßn GEMINI_API_KEY ƒë·ªÉ s·ª≠ d·ª•ng AI Insights")

elif workflow_step == "üé® Step 4: Dashboard Blueprint":
    st.markdown("""
    <div class="step-card">
        <h2>üé® B∆∞·ªõc 4: Dashboard Blueprint</h2>
        <p>AI Expert t·ª± ƒë·ªông thi·∫øt k·∫ø dashboard v·ªõi OQMLB framework</p>
    </div>
    """, unsafe_allow_html=True)
    
    if st.session_state.cleaned_data is None:
        st.warning("‚ö†Ô∏è Vui l√≤ng ho√†n th√†nh Step 3 tr∆∞·ªõc!")
    else:
        # Initialize OQMLB session state keys
        if 'oqmlb_objectives' not in st.session_state:
            st.session_state.oqmlb_objectives = None
        if 'oqmlb_questions' not in st.session_state:
            st.session_state.oqmlb_questions = None
        if 'oqmlb_metrics' not in st.session_state:
            st.session_state.oqmlb_metrics = None
        if 'oqmlb_layout' not in st.session_state:
            st.session_state.oqmlb_layout = None
        if 'oqmlb_build' not in st.session_state:
            st.session_state.oqmlb_build = None
        
        client = init_gemini()
        
        if client:
            # Main AI Generation Button
            st.markdown("### ü§ñ AI Expert Dashboard Designer")
            st.info("üí° **AI Expert Mode**: H·ªá th·ªëng AI s·∫Ω ƒë√≥ng vai tr√≤ chuy√™n gia Dashboard Design ƒë·ªÉ t·ª± ƒë·ªông t·∫°o to√†n b·ªô OQMLB Blueprint chuy√™n nghi·ªáp. B·∫°n ch·ªâ c·∫ßn review v√† ch·ªânh s·ª≠a n·∫øu mu·ªën.")
            
            col1, col2 = st.columns([3, 1])
            with col1:
                if st.button("üöÄ AI T·∫°o Dashboard Blueprint T·ª± ƒê·ªông (Expert Mode)", type="primary", width='stretch'):
                    try:
                        with st.spinner("üéØ AI Expert ƒëang ph√¢n t√≠ch d·ªØ li·ªáu v√† thi·∫øt k·∫ø dashboard chuy√™n nghi·ªáp..."):
                            df = st.session_state.cleaned_data
                            
                            # Comprehensive Expert Prompt
                            expert_prompt = f"""
B·∫°n l√† Senior Dashboard Design Consultant v·ªõi 15+ nƒÉm kinh nghi·ªám trong Business Intelligence v√† Data Visualization. 
Nhi·ªám v·ª• c·ªßa b·∫°n l√† thi·∫øt k·∫ø m·ªôt Dashboard Blueprint ho√†n ch·ªânh, chuy√™n nghi·ªáp theo framework OQMLB.

**TH√îNG TIN D·ªÆ LI·ªÜU:**
- Dataset: {st.session_state.dataset_description}
- M·ª•c ti√™u ph√¢n t√≠ch: {st.session_state.analysis_goal}
- S·ªë l∆∞·ª£ng records: {len(df)}
- Columns: {df.columns.tolist()}
- Numerical columns: {st.session_state.numerical_cols}
- Categorical columns: {st.session_state.categorical_cols}
- Date/Time columns: {st.session_state.date_cols}

**D·ªØ li·ªáu m·∫´u:**
{df.head(10).to_string()}

**Y√äU C·∫¶U THI·∫æT K·∫æ OQMLB FRAMEWORK:**

H√£y t·∫°o m·ªôt Dashboard Blueprint ho√†n ch·ªânh theo c·∫•u tr√∫c sau (b·∫Øt bu·ªôc ph·∫£i c√≥ ƒë·∫ßy ƒë·ªß 5 ph·∫ßn):

## O - OBJECTIVES (M·ª•c ti√™u)
- Dashboard purpose: M·ª•c ƒë√≠ch ch√≠nh c·ªßa dashboard n√†y
- Target audience: ƒê·ªëi t∆∞·ª£ng s·ª≠ d·ª•ng (role, level)
- Key business goals: 3-5 m·ª•c ti√™u kinh doanh c·ªët l√µi
- Success criteria: Ti√™u ch√≠ ƒë√°nh gi√° th√†nh c√¥ng

## Q - QUESTIONS (C√¢u h·ªèi c·∫ßn tr·∫£ l·ªùi)
Chia th√†nh 5 nh√≥m c√¢u h·ªèi (m·ªói nh√≥m 3-5 c√¢u):
1. **T·ªïng quan (Overview)**: C√¢u h·ªèi v·ªÅ t√¨nh h√¨nh chung
2. **Hi·ªáu su·∫•t (Performance)**: ƒêo l∆∞·ªùng KPIs v√† metrics
3. **Xu h∆∞·ªõng (Trends)**: Patterns theo th·ªùi gian
4. **So s√°nh (Comparison)**: So s√°nh gi·ªØa c√°c segments
5. **H√†nh ƒë·ªông (Action)**: Insights ƒë·ªÉ ra quy·∫øt ƒë·ªãnh

## M - METRICS (Ch·ªâ s·ªë ƒëo l∆∞·ªùng)

**‚≠ê PRIMARY KPIs** (3-5 ch·ªâ s·ªë quan tr·ªçng nh·∫•t - theo th·ª© t·ª± ∆∞u ti√™n):
V·ªõi m·ªói Primary KPI, cung c·∫•p:
- **KPI Name**: T√™n metric
- **Priority**: [P1/P2/P3] - P1 l√† quan tr·ªçng nh·∫•t (Hero KPI), P2-P3 supporting
- **Formula**: C√¥ng th·ª©c t√≠nh (n·∫øu c·∫ßn)
- **Target/Threshold**: M·ª•c ti√™u ho·∫∑c ng∆∞·ª°ng c·∫£nh b√°o c·ª• th·ªÉ
- **Business Question Answered**: Link ƒë·∫øn c√¢u h·ªèi n√†o trong ph·∫ßn Q
- **Action Recommendation**: 
  * N·∫øu metric > threshold ‚Üí N√™n l√†m g√¨
  * N·∫øu metric < threshold ‚Üí N√™n l√†m g√¨
  * Xu h∆∞·ªõng t·ªët/x·∫•u l√† g√¨

**Secondary Metrics** (metrics h·ªó tr·ª£):
- Li·ªát k√™ v·ªõi c√¥ng th·ª©c

**Calculated Metrics** (c·∫ßn t√≠nh to√°n):
- C√¥ng th·ª©c chi ti·∫øt ƒë·ªÉ implement

## L - LAYOUT (B·ªë c·ª•c Dashboard)

**üé® DESIGN PRINCIPLES (B·∫ÆT BU·ªòC):**
- **F-Pattern Layout**: Hero KPI (P1) ph·∫£i ·ªü top-left, ng∆∞·ªùi d√πng ƒë·ªçc t·ª´ tr√°i‚Üíph·∫£i, tr√™n‚Üíd∆∞·ªõi
- **Visual Hierarchy**: Metrics quan tr·ªçng h∆°n ‚Üí k√≠ch th∆∞·ªõc l·ªõn h∆°n, v·ªã tr√≠ n·ªïi b·∫≠t h∆°n
- **Clarity First**: Limit 6-8 visualizations per page, tr√°nh overcrowd
- **Whitespace**: Kho·∫£ng tr·∫Øng gi·ªØa components ƒë·ªÉ d·ªÖ ƒë·ªçc
- **Color Consistency**: T·ªëi ƒëa 3-4 m√†u ch√≠nh, s·ª≠ d·ª•ng nh·∫•t qu√°n

**üì± PAGE STRUCTURE** (thi·∫øt k·∫ø 3-4 pages/tabs):

**Page [X]: [T√™n trang]**
- **Purpose**: M·ª•c ƒë√≠ch v√† target users
- **Hero Section** (Top-Left, most prominent):
  * Primary KPI (P1): [T√™n KPI] - Large metric card v·ªõi trend indicator
- **Supporting KPIs** (Top-Right, secondary prominence):
  * 2-3 P2/P3 KPIs - Medium size cards
- **Visualizations** (Main content area, limit 4-6 charts):
  * Chart 1: [Type] - [Data] - [Insight] - [Position: left/right/center]
  * Chart 2: [Type] - [Data] - [Insight] - [Position: ...]
  * (Max 6 charts - prioritize quality over quantity)
- **Contextual Filters** (Sidebar or top):
  * Filter 1: [Category/Time range] - Default value
  * Filter 2: [Segment/Region] - Options
- **AI Insights Panel** (Right sidebar or bottom):
  * Key findings t·ª´ data
  * Action recommendations based on current metrics
- **Layout Grid**: 
  * Row 1: Hero KPI (col-span-2) + Supporting KPIs (col-span-1 each)
  * Row 2-3: Main visualizations (balanced grid)
  * Row 4: Details/drill-down section

## B - BUILD (H∆∞·ªõng d·∫´n tri·ªÉn khai)
- **Data preparation**: X·ª≠ l√Ω data c·∫ßn thi·∫øt
- **Technology stack**: Tools/platforms ƒë·ªÅ xu·∫•t (Streamlit, PowerBI, Tableau, etc.)
- **Implementation priority**: Phases tri·ªÉn khai (Phase 1, 2, 3)
- **Best practices**: Guidelines cho developers
- **Performance considerations**: Optimize queries, caching
- **Testing checklist**: C√°c ƒëi·ªÉm c·∫ßn test

**Y√äU C·∫¶U OUTPUT (B·∫ÆT BU·ªòC):**
- Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát
- Professional, chi ti·∫øt, actionable
- Format Markdown ƒë·∫πp v·ªõi headers, bullet points, tables n·∫øu c·∫ßn
- ƒê∆∞a ra recommendations c·ª• th·ªÉ d·ª±a tr√™n data th·ª±c t·∫ø
- Apply best practices trong Dashboard Design (Gestalt principles, color theory, data-ink ratio)

**‚ú® 5 TI√äU CH√ç CH·∫§T L∆Ø·ª¢NG DASHBOARD (ph·∫£i ƒë√°p ·ª©ng):**
1. ‚ù∂ **Informative**: M·ªói chart/KPI ph·∫£i tr·∫£ l·ªùi r√µ r√†ng business question n√†o
2. ‚ù∑ **Clarity**: D·ªÖ hi·ªÉu trong 5-10 gi√¢y, chart types ph√π h·ª£p, hierarchy r√µ r√†ng
3. ‚ù∏ **Design**: F-pattern layout, whitespace h·ª£p l√Ω, color consistency
4. ‚ùπ **Interactivity**: Filters c√≥ context, drill-down paths r√µ r√†ng
5. ‚ù∫ **Actionable Insights**: M·ªói metric ph·∫£i c√≥ action recommendations - "N·∫øu X th√¨ l√†m Y"

**FORMAT TEMPLATE B·∫ÆT BU·ªòC (KH√îNG ƒê∆Ø·ª¢C THAY ƒê·ªîI HEADERS):**
B·∫°n PH·∫¢I s·ª≠ d·ª•ng ch√≠nh x√°c c√°c headers sau (bao g·ªìm c·∫£ d·∫•u ##):

## O - OBJECTIVES
[N·ªôi dung v·ªÅ objectives...]

## Q - QUESTIONS
[N·ªôi dung v·ªÅ questions...]

## M - METRICS
[N·ªôi dung v·ªÅ metrics...]

## L - LAYOUT
[N·ªôi dung v·ªÅ layout...]

## B - BUILD
[N·ªôi dung v·ªÅ build...]

QUAN TR·ªåNG: Ph·∫£i c√≥ ƒë·∫ßy ƒë·ªß 5 sections v·ªõi headers ch√≠nh x√°c nh∆∞ tr√™n.
                            """
                            
                            # Generate complete OQMLB (needs more tokens for comprehensive blueprint)
                            success, full_blueprint = generate_ai_insight(client, expert_prompt, temperature=0.5, max_tokens=8192)
                            
                            if not success:
                                st.error(f"‚ùå {full_blueprint}")
                                st.warning("üí° Vui l√≤ng ki·ªÉm tra GEMINI_API_KEY ho·∫∑c th·ª≠ l·∫°i sau.")
                                st.stop()
                            
                            # Parse sections with improved logic
                            sections = full_blueprint.split('## ')
                            
                            # Reset sections first
                            st.session_state.oqmlb_objectives = None
                            st.session_state.oqmlb_questions = None
                            st.session_state.oqmlb_metrics = None
                            st.session_state.oqmlb_layout = None
                            st.session_state.oqmlb_build = None
                            
                            # Debug: Show what sections were found
                            section_headers = [s.split('\n')[0][:50] for s in sections if s.strip()]
                            
                            for section in sections:
                                section_text = section.strip()
                                if section_text:
                                    section_upper = section_text.upper()
                                    
                                    # More flexible parsing - check if starts with O/Q/M/L/B
                                    if section_upper.startswith('O -') or section_upper.startswith('OBJECTIVES'):
                                        st.session_state.oqmlb_objectives = '## ' + section_text
                                    elif section_upper.startswith('Q -') or section_upper.startswith('QUESTIONS'):
                                        st.session_state.oqmlb_questions = '## ' + section_text
                                    elif section_upper.startswith('M -') or section_upper.startswith('METRICS'):
                                        st.session_state.oqmlb_metrics = '## ' + section_text
                                    elif section_upper.startswith('L -') or section_upper.startswith('LAYOUT'):
                                        st.session_state.oqmlb_layout = '## ' + section_text
                                    elif section_upper.startswith('B -') or section_upper.startswith('BUILD'):
                                        st.session_state.oqmlb_build = '## ' + section_text
                            
                            # Store complete blueprint
                            st.session_state.dashboard_blueprint = full_blueprint
                            
                            # Validate all sections are present
                            missing_sections = []
                            if not st.session_state.oqmlb_objectives:
                                missing_sections.append("Objectives")
                            if not st.session_state.oqmlb_questions:
                                missing_sections.append("Questions")
                            if not st.session_state.oqmlb_metrics:
                                missing_sections.append("Metrics")
                            if not st.session_state.oqmlb_layout:
                                missing_sections.append("Layout")
                            if not st.session_state.oqmlb_build:
                                missing_sections.append("Build")
                            
                            if missing_sections:
                                st.warning(f"‚ö†Ô∏è M·ªôt s·ªë sections ch∆∞a ƒë∆∞·ª£c parse ƒë√∫ng: {', '.join(missing_sections)}.")
                                st.info(f"üìã Headers t√¨m th·∫•y: {', '.join(section_headers[:10])}")
                                st.info("üí° Xem to√†n b·ªô blueprint ·ªü tab 'Complete Blueprint' b√™n d∆∞·ªõi.")
                            else:
                                st.success("‚úÖ AI Expert ƒë√£ t·∫°o xong Dashboard Blueprint chuy√™n nghi·ªáp!")
                            
                            # Parse structured data for Step 5 dashboard generation
                            try:
                                structured_data = parse_blueprint_structured_data(
                                    st.session_state.oqmlb_metrics or "",
                                    st.session_state.oqmlb_layout or ""
                                )
                                st.session_state.blueprint_structured_data = structured_data
                                
                                # Debug info
                                if structured_data.get('hero_kpi'):
                                    st.info(f"üéØ Hero KPI detected: {structured_data['hero_kpi'].get('name', 'N/A')}")
                            except Exception as e:
                                st.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ parse structured data: {str(e)}")
                                st.session_state.blueprint_structured_data = None
                            
                            st.rerun()
                    
                    except Exception as e:
                        st.error(f"‚ùå L·ªói khi t·∫°o blueprint: {str(e)}")
                        st.error("Vui l√≤ng th·ª≠ l·∫°i ho·∫∑c ki·ªÉm tra k·∫øt n·ªëi internet v√† GEMINI_API_KEY.")
            
            with col2:
                if st.button("üîÑ Reset", width='stretch'):
                    st.session_state.oqmlb_objectives = None
                    st.session_state.oqmlb_questions = None
                    st.session_state.oqmlb_metrics = None
                    st.session_state.oqmlb_layout = None
                    st.session_state.oqmlb_build = None
                    st.session_state.dashboard_blueprint = None
                    st.rerun()
            
            st.markdown("---")
            
            # Display OQMLB Framework in tabs
            if st.session_state.oqmlb_objectives:
                st.markdown("### üìã OQMLB Framework (AI Generated)")
                
                framework_tabs = st.tabs([
                    "üéØ Objectives",
                    "‚ùì Questions", 
                    "üìä Metrics",
                    "üìê Layout",
                    "üî® Build",
                    "üì• Complete Blueprint"
                ])
                
                with framework_tabs[0]:  # Objectives
                    st.markdown(st.session_state.oqmlb_objectives)
                    
                    with st.expander("‚úèÔ∏è Ch·ªânh s·ª≠a Objectives"):
                        edited_obj = st.text_area(
                            "Edit n·ªôi dung:",
                            value=st.session_state.oqmlb_objectives,
                            height=300,
                            key="edit_objectives"
                        )
                        if st.button("üíæ L∆∞u thay ƒë·ªïi", key="save_obj"):
                            st.session_state.oqmlb_objectives = edited_obj
                            st.success("ƒê√£ l∆∞u!")
                
                with framework_tabs[1]:  # Questions
                    st.markdown(st.session_state.oqmlb_questions if st.session_state.oqmlb_questions else "_Ch∆∞a c√≥ d·ªØ li·ªáu_")
                    
                    with st.expander("‚úèÔ∏è Ch·ªânh s·ª≠a Questions"):
                        edited_q = st.text_area(
                            "Edit n·ªôi dung:",
                            value=st.session_state.oqmlb_questions or "",
                            height=300,
                            key="edit_questions"
                        )
                        if st.button("üíæ L∆∞u thay ƒë·ªïi", key="save_q"):
                            st.session_state.oqmlb_questions = edited_q
                            st.success("ƒê√£ l∆∞u!")
                
                with framework_tabs[2]:  # Metrics
                    st.markdown(st.session_state.oqmlb_metrics if st.session_state.oqmlb_metrics else "_Ch∆∞a c√≥ d·ªØ li·ªáu_")
                    
                    with st.expander("‚úèÔ∏è Ch·ªânh s·ª≠a Metrics"):
                        edited_m = st.text_area(
                            "Edit n·ªôi dung:",
                            value=st.session_state.oqmlb_metrics or "",
                            height=300,
                            key="edit_metrics"
                        )
                        if st.button("üíæ L∆∞u thay ƒë·ªïi", key="save_m"):
                            st.session_state.oqmlb_metrics = edited_m
                            st.success("ƒê√£ l∆∞u!")
                
                with framework_tabs[3]:  # Layout
                    st.markdown(st.session_state.oqmlb_layout if st.session_state.oqmlb_layout else "_Ch∆∞a c√≥ d·ªØ li·ªáu_")
                    
                    with st.expander("‚úèÔ∏è Ch·ªânh s·ª≠a Layout"):
                        edited_l = st.text_area(
                            "Edit n·ªôi dung:",
                            value=st.session_state.oqmlb_layout or "",
                            height=300,
                            key="edit_layout"
                        )
                        if st.button("üíæ L∆∞u thay ƒë·ªïi", key="save_l"):
                            st.session_state.oqmlb_layout = edited_l
                            st.success("ƒê√£ l∆∞u!")
                
                with framework_tabs[4]:  # Build
                    st.markdown(st.session_state.oqmlb_build if st.session_state.oqmlb_build else "_Ch∆∞a c√≥ d·ªØ li·ªáu_")
                    
                    with st.expander("‚úèÔ∏è Ch·ªânh s·ª≠a Build"):
                        edited_b = st.text_area(
                            "Edit n·ªôi dung:",
                            value=st.session_state.oqmlb_build or "",
                            height=300,
                            key="edit_build"
                        )
                        if st.button("üíæ L∆∞u thay ƒë·ªïi", key="save_b"):
                            st.session_state.oqmlb_build = edited_b
                            st.success("ƒê√£ l∆∞u!")
                
                with framework_tabs[5]:  # Complete Blueprint
                    st.markdown("### üìã Dashboard Blueprint Ho√†n Ch·ªânh")
                    
                    if st.session_state.dashboard_blueprint:
                        st.markdown(st.session_state.dashboard_blueprint)
                        
                        # Download options
                        st.markdown("---")
                        st.markdown("### üì• T·∫£i xu·ªëng Blueprint")
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            st.download_button(
                                label="üì• Download Blueprint (.md)",
                                data=st.session_state.dashboard_blueprint,
                                file_name=f"dashboard_blueprint_{datetime.now().strftime('%Y%m%d_%H%M')}.md",
                                mime="text/markdown",
                                width='stretch'
                            )
                        
                        with col2:
                            # Also offer TXT format
                            st.download_button(
                                label="üìÑ Download Blueprint (.txt)",
                                data=st.session_state.dashboard_blueprint,
                                file_name=f"dashboard_blueprint_{datetime.now().strftime('%Y%m%d_%H%M')}.txt",
                                mime="text/plain",
                                width='stretch'
                            )
            else:
                st.info("üëÜ Click n√∫t **'üöÄ AI T·∫°o Dashboard Blueprint T·ª± ƒê·ªông'** ƒë·ªÉ AI Expert t·∫°o blueprint chuy√™n nghi·ªáp cho b·∫°n!")
        
        else:
            st.error("‚ùå C·∫ßn GEMINI_API_KEY ƒë·ªÉ s·ª≠ d·ª•ng AI Expert Dashboard Designer")
            st.info("üí° Vui l√≤ng c·∫•u h√¨nh GEMINI_API_KEY trong Secrets ƒë·ªÉ k√≠ch ho·∫°t t√≠nh nƒÉng n√†y.")

elif workflow_step == "üöÄ Step 5: Build Dashboard":
    st.markdown("""
    <div class="step-card">
        <h2>üöÄ B∆∞·ªõc 5: Auto-Generated Interactive Dashboard</h2>
        <p>‚ú® Dashboard ƒë∆∞·ª£c t·∫°o t·ª± ƒë·ªông t·ª´ AI Blueprint c·ªßa b·∫°n</p>
    </div>
    """, unsafe_allow_html=True)
    
    if st.session_state.cleaned_data is None:
        st.warning("‚ö†Ô∏è Vui l√≤ng ho√†n th√†nh Step 2 (Data Cleaning) tr∆∞·ªõc!")
    else:
        df = st.session_state.cleaned_data
        
        # Success message
        st.success("‚úÖ Dashboard ƒë√£ ƒë∆∞·ª£c t·∫°o t·ª± ƒë·ªông t·ª´ OQMLB Blueprint!")
        
        # Dashboard tabs based on common structure
        dashboard_tabs = st.tabs([
            "üìä Overview Dashboard",
            "üìà Detailed Analysis", 
            "üéØ KPIs & Metrics",
            "üì• Export & Code"
        ])
        
        with dashboard_tabs[0]:  # Overview Dashboard
            st.markdown("### üìä Executive Dashboard")
            st.markdown("*T·ª± ƒë·ªông t·∫°o theo OQMLB Blueprint + 5 Ti√™u Ch√≠ Chuy√™n Nghi·ªáp*")
            
            # AI Dashboard Insights (Bricks.ai-inspired feature)
            st.markdown("---")
            client = init_gemini()
            if client:
                # Handle regeneration or first-time generation
                should_generate = False
                is_regenerating = False
                
                if st.session_state.regenerate_insights_flag:
                    st.session_state.regenerate_insights_flag = False
                    should_generate = True
                    is_regenerating = True
                
                # Show UI based on current state
                if not st.session_state.dashboard_insights and not should_generate:
                    # No insights yet - show generate button
                    if st.button("ü§ñ Generate AI Dashboard Insights", type="primary", use_container_width=True, help="AI ph√¢n t√≠ch to√†n b·ªô dashboard v√† t·∫°o insights v·ªõi specific numbers"):
                        should_generate = True
                    
                    st.info("üí° Click **'Generate AI Dashboard Insights'** ƒë·ªÉ AI ph√¢n t√≠ch to√†n b·ªô dashboard v·ªõi specific numbers (gi·ªëng Bricks.ai)")
                
                elif st.session_state.dashboard_insights and not should_generate:
                    # Insights available - show with regenerate option
                    col_success, col_regen = st.columns([3, 2])
                    with col_success:
                        st.success("‚úÖ AI Dashboard Insights ƒë√£ s·∫µn s√†ng!")
                    with col_regen:
                        if st.button("üîÑ Regenerate Insights", use_container_width=True):
                            st.session_state.regenerate_insights_flag = True
                            st.rerun()
                    
                    with st.expander("üí° AI Dashboard Insights (Bricks.ai Style)", expanded=True):
                        st.markdown(st.session_state.dashboard_insights)
                
                # Execute generation if triggered
                if should_generate:
                    spinner_msg = "üîÑ AI ƒëang regenerate insights..." if is_regenerating else "ü§ñ AI ƒëang ph√¢n t√≠ch dashboard data..."
                    with st.spinner(spinner_msg):
                        success, insights = generate_dashboard_insights(
                            client,
                            df,
                            st.session_state.numerical_cols or [],
                            st.session_state.categorical_cols or []
                        )
                        if success:
                            st.session_state.dashboard_insights = insights
                            st.rerun()
                        else:
                            st.error(f"‚ùå L·ªói: {insights}")
                            if is_regenerating:
                                st.warning("üí° Regeneration failed, keeping old insights")
                            st.stop()
                
                st.markdown("---")
                
                # Per-Chart Insights (Bricks.ai per-visual insights)
                st.markdown("#### üí° Per-Chart Insights (Bricks.ai Style)")
                st.caption("*Insights cho T·ª™NG chart - gi·ªëng Bricks.ai professional reports*")
                
                # Handle regeneration for per-chart insights
                should_generate_charts = False
                is_regenerating_charts = False
                
                if st.session_state.regenerate_chart_insights_flag:
                    st.session_state.regenerate_chart_insights_flag = False
                    should_generate_charts = True
                    is_regenerating_charts = True
                
                # Show UI based on current state
                if not st.session_state.per_chart_insights and not should_generate_charts:
                    col_gen_chart = st.columns(1)[0]
                    if st.button("‚ú® Generate Per-Chart Insights", type="secondary", use_container_width=True, help="AI t·∫°o insights ri√™ng cho T·ª™NG chart (2-3 bullets per visual)"):
                        should_generate_charts = True
                    
                    st.info("‚ú® Click ƒë·ªÉ t·∫°o insights box b√™n c·∫°nh m·ªói chart (Bricks.ai format)")
                
                elif st.session_state.per_chart_insights and not should_generate_charts:
                    col_chart_success, col_chart_regen = st.columns([3, 2])
                    with col_chart_success:
                        st.success(f"‚úÖ Per-Chart Insights generated cho {len(st.session_state.per_chart_insights)} charts!")
                    with col_chart_regen:
                        if st.button("üîÑ Regenerate Per-Chart", use_container_width=True):
                            st.session_state.regenerate_chart_insights_flag = True
                            st.rerun()
                
                # Execute generation if triggered
                if should_generate_charts:
                    spinner_msg = "üîÑ AI ƒëang regenerate per-chart insights..." if is_regenerating_charts else "‚ú® AI ƒëang t·∫°o insights cho t·ª´ng chart..."
                    with st.spinner(spinner_msg):
                        success, insights_dict = generate_per_chart_insights(
                            client,
                            df,
                            st.session_state.numerical_cols or [],
                            st.session_state.categorical_cols or []
                        )
                        if success:
                            st.session_state.per_chart_insights = insights_dict
                            st.rerun()
                        else:
                            st.error("‚ùå L·ªói khi generate per-chart insights")
                            if is_regenerating_charts:
                                st.warning("üí° Regeneration failed, keeping old insights")
                            st.stop()
            
            st.markdown("---")
            
            # üéØ PHASE 1: INTERACTIVE FILTER PANEL (Better than Bricks.ai click-to-filter!)
            st.markdown("### üîç Interactive Data Filters")
            st.caption("*Filter to√†n b·ªô dashboard - t·∫•t c·∫£ charts s·∫Ω update real-time*")
            
            # Create filter UI
            filter_col1, filter_col2, filter_col3 = st.columns([3, 3, 1])
            
            with filter_col1:
                # Categorical filters
                if st.session_state.categorical_cols:
                    selected_cat_col = st.selectbox(
                        "üìä Filter by Category",
                        options=["(No filter)"] + st.session_state.categorical_cols,
                        key="filter_cat_col"
                    )
                    
                    if selected_cat_col != "(No filter)":
                        unique_vals = df[selected_cat_col].unique().tolist()
                        selected_vals = st.multiselect(
                            f"Select {selected_cat_col} values:",
                            options=unique_vals,
                            default=st.session_state.active_filters.get(selected_cat_col, unique_vals),
                            key=f"filter_{selected_cat_col}"
                        )
                        st.session_state.active_filters[selected_cat_col] = selected_vals
                    else:
                        # Clear categorical filters
                        for col in st.session_state.categorical_cols:
                            if col in st.session_state.active_filters:
                                del st.session_state.active_filters[col]
            
            with filter_col2:
                # Numerical range filters
                if st.session_state.numerical_cols:
                    selected_num_col = st.selectbox(
                        "üìà Filter by Range",
                        options=["(No filter)"] + st.session_state.numerical_cols,
                        key="filter_num_col"
                    )
                    
                    if selected_num_col != "(No filter)":
                        col_min = float(df[selected_num_col].min())
                        col_max = float(df[selected_num_col].max())
                        default_range = st.session_state.active_filters.get(f"{selected_num_col}_range", (col_min, col_max))
                        
                        selected_range = st.slider(
                            f"{selected_num_col} range:",
                            min_value=col_min,
                            max_value=col_max,
                            value=default_range,
                            key=f"range_{selected_num_col}"
                        )
                        st.session_state.active_filters[f"{selected_num_col}_range"] = selected_range
                        st.session_state.active_filters[f"{selected_num_col}_range_col"] = selected_num_col
                    else:
                        # Clear numerical filters
                        for key in list(st.session_state.active_filters.keys()):
                            if key.endswith('_range') or key.endswith('_range_col'):
                                del st.session_state.active_filters[key]
            
            with filter_col3:
                st.write("")  # Spacing
                st.write("")  # Spacing
                if st.button("üîÑ Clear All", help="Reset t·∫•t c·∫£ filters"):
                    st.session_state.active_filters = {}
                    st.rerun()
            
            # Apply filters to dataframe
            filtered_df = df.copy()
            active_filter_count = 0
            
            # Apply categorical filters
            for col in st.session_state.categorical_cols:
                if col in st.session_state.active_filters and st.session_state.active_filters[col]:
                    filtered_df = filtered_df[filtered_df[col].isin(st.session_state.active_filters[col])]
                    active_filter_count += 1
            
            # Apply numerical range filters
            for key, value in list(st.session_state.active_filters.items()):
                if key.endswith('_range_col'):
                    range_col = value
                    range_key = key.replace('_range_col', '_range')
                    if range_key in st.session_state.active_filters:
                        min_val, max_val = st.session_state.active_filters[range_key]
                        filtered_df = filtered_df[
                            (filtered_df[range_col] >= min_val) & (filtered_df[range_col] <= max_val)
                        ]
                        active_filter_count += 1
            
            # Show filter status
            if active_filter_count > 0:
                st.success(f"‚úÖ {active_filter_count} filter(s) active | Showing {len(filtered_df):,} / {len(df):,} records ({len(filtered_df)/len(df)*100:.1f}%)")
            else:
                st.info("‚ÑπÔ∏è No filters applied - showing all data")
            
            # Use filtered dataframe for all visualizations below
            df = filtered_df
            
            st.markdown("---")
            
            # ‚ù∂ INFORMATIVE: Get structured data from blueprint
            blueprint_data = st.session_state.blueprint_structured_data
            
            # F-PATTERN LAYOUT: Hero KPI (top-left) + Supporting KPIs (top-right)
            if st.session_state.numerical_cols:
                st.markdown("#### üéØ Key Performance Indicators")
                
                # Check if we have parsed blueprint KPIs
                if blueprint_data and blueprint_data.get('primary_kpis'):
                    primary_kpis = blueprint_data['primary_kpis'][:5]  # Max 5 KPIs
                    hero_kpi = blueprint_data.get('hero_kpi')  # P1 priority
                    
                    # Hero KPI Section (top-left, prominent)
                    if hero_kpi and hero_kpi.get('name'):
                        st.markdown(f"##### üèÜ {hero_kpi['name']} (Primary)")
                        
                        # Find matching column for hero KPI (with safety checks)
                        hero_col = None
                        if st.session_state.numerical_cols:
                            for col in st.session_state.numerical_cols:
                                if hero_kpi['name'].lower() in col.lower() or col.lower() in hero_kpi['name'].lower():
                                    hero_col = col
                                    break
                            
                            if not hero_col:
                                hero_col = st.session_state.numerical_cols[0]
                        
                        if hero_col:
                            hero_val = df[hero_col].sum()
                            hero_avg = df[hero_col].mean()
                            
                            # Large hero metric card
                            col_hero, col_insight = st.columns([2, 3])
                            with col_hero:
                                st.metric(
                                    label=f"{hero_col.replace('_', ' ').title()}",
                                    value=f"{hero_val:,.0f}" if hero_val > 1000 else f"{hero_val:.2f}",
                                    delta=f"Avg: {hero_avg:.1f}",
                                    help=f"‚≠ê Primary KPI - Priority P1"
                                )
                        
                            # ‚ù∫ ACTIONABLE INSIGHTS: Show recommendations
                            with col_insight:
                                action_rec = hero_kpi.get('action_recommendations') or ""
                                threshold = hero_kpi.get('threshold') or ""
                                
                                if action_rec:
                                    st.info(f"üí° **Action Recommendation:**\n\n{str(action_rec)[:200]}...")
                                elif threshold:
                                    st.info(f"üéØ **Target:** {str(threshold)}")
                            
                            st.markdown("---")
                    
                    # Supporting KPIs (P2, P3)
                    supporting_kpis = [kpi for kpi in primary_kpis if kpi.get('priority') in ['P2', 'P3']][:4]
                    if supporting_kpis:
                        st.markdown("##### üìä Supporting Metrics")
                        kpi_cols = st.columns(len(supporting_kpis))
                        
                        for i, kpi in enumerate(supporting_kpis):
                            with kpi_cols[i]:
                                # Match KPI to column (with safety)
                                matched_col = None
                                if st.session_state.numerical_cols:
                                    for col in st.session_state.numerical_cols:
                                        if kpi['name'].lower() in col.lower() or col.lower() in kpi['name'].lower():
                                            matched_col = col
                                            break
                                    
                                    if not matched_col and i < len(st.session_state.numerical_cols):
                                        matched_col = st.session_state.numerical_cols[i]
                                
                                if matched_col and matched_col in df.columns:
                                    val = df[matched_col].mean()
                                    std = df[matched_col].std()
                                    
                                    # ‚ù∏ DESIGN: Color coding based on priority
                                    priority_emoji = "ü•à" if kpi.get('priority') == 'P2' else "ü•â"
                                    
                                    st.metric(
                                        label=f"{priority_emoji} {matched_col.replace('_', ' ').title()}",
                                        value=f"{val:,.0f}" if val > 1000 else f"{val:.2f}",
                                        delta=f"¬±{std:.1f}",
                                        help=f"Priority: {kpi.get('priority', 'P2')}\nTarget: {kpi.get('threshold', 'N/A')}"
                                    )
                else:
                    # Fallback: Use numerical columns directly
                    num_kpis = min(4, len(st.session_state.numerical_cols))
                    kpi_cols = st.columns(num_kpis)
                    
                    for i, col_name in enumerate(st.session_state.numerical_cols[:num_kpis]):
                        with kpi_cols[i]:
                            col_mean = df[col_name].mean()
                            col_std = df[col_name].std()
                            col_min = df[col_name].min()
                            col_max = df[col_name].max()
                            
                            st.metric(
                                label=col_name.replace('_', ' ').title(),
                                value=f"{col_mean:,.0f}" if col_mean > 1000 else f"{col_mean:.2f}",
                                delta=f"¬±{col_std:.1f}",
                                help=f"Min: {col_min:,.0f} | Max: {col_max:,.0f}"
                            )
            
            st.markdown("---")
            
            # ‚ù∫ ACTIONABLE INSIGHTS PANEL
            if blueprint_data and blueprint_data.get('primary_kpis'):
                with st.expander("üí° AI Insights & Recommendations", expanded=False):
                    st.markdown("### üéØ Key Findings & Next Actions")
                    
                    for kpi in blueprint_data['primary_kpis'][:3]:
                        if kpi.get('action_recommendations'):
                            st.markdown(f"**{kpi['name']}:**")
                            st.write(kpi['action_recommendations'])
                            st.markdown("---")
            
            st.markdown("---")
            
            # ‚ù∑ CLARITY: Main Visualizations (Chart Selection Rules)
            st.markdown("### üìà Key Visualizations")
            st.caption("*Charts t·ª± ƒë·ªông ch·ªçn theo best practices: Line for trends, Bar for comparisons*")
            
            if st.session_state.numerical_cols and len(st.session_state.numerical_cols) >= 2:
                # Chart 1: Trend Line Chart (Bricks.ai layout: Chart | Insights)
                st.markdown("#### üìà Trend Analysis")
                st.caption("‚ùì **Answers:** How is performance changing over time?")
                
                chart_col, insights_col = st.columns([2.5, 1.5])
                
                with chart_col:
                    # LINE CHART - For showing trends over time (Edward Tufte guideline)
                    fig = px.line(
                        df.reset_index(), 
                        y=st.session_state.numerical_cols[0],
                        title=f"{st.session_state.numerical_cols[0].replace('_', ' ').title()} Trend",
                        labels={'index': 'Record #', st.session_state.numerical_cols[0]: st.session_state.numerical_cols[0].replace('_', ' ').title()}
                    )
                    # ‚ù∏ DESIGN: Semantic colors (Blue = neutral/informational)
                    fig.update_traces(line_color='#0066CC', line_width=3)
                    fig.update_layout(
                        title_font_size=18,
                        title_font_family="Arial",
                        showlegend=False,
                        margin=dict(t=50, b=50, l=50, r=20)  # Whitespace
                    )
                    st.plotly_chart(fig, use_container_width=True)
                
                with insights_col:
                    # Display insights if available
                    if st.session_state.per_chart_insights.get('trend_chart'):
                        st.markdown("""
                        <div style="background-color: #f0f8ff !important; border-left: 4px solid #0066CC !important; padding: 15px !important; border-radius: 5px !important; margin-top: 20px !important;">
                            <p style="margin: 0 !important; font-size: 14px !important; font-weight: 600 !important; color: #0066CC !important; margin-bottom: 10px !important;">üí° Key Insights</p>
                        """, unsafe_allow_html=True)
                        st.markdown(st.session_state.per_chart_insights['trend_chart'])
                        st.markdown("</div>", unsafe_allow_html=True)
                    else:
                        st.info("üí° Generate Per-Chart Insights ƒë·ªÉ xem insights ri√™ng cho chart n√†y")
                
                st.markdown("---")
                
                # Chart 2: Distribution Histogram (Bricks.ai layout: Chart | Insights)
                st.markdown("#### üìä Distribution Analysis")
                st.caption("‚ùì **Answers:** What is the value distribution?")
                
                chart_col2, insights_col2 = st.columns([2.5, 1.5])
                
                with chart_col2:
                    # HISTOGRAM - For showing distribution patterns
                    fig = px.histogram(
                        df, 
                        x=st.session_state.numerical_cols[min(1, len(st.session_state.numerical_cols)-1)],
                        title=f"{st.session_state.numerical_cols[min(1, len(st.session_state.numerical_cols)-1)].replace('_', ' ').title()} Distribution",
                        labels={st.session_state.numerical_cols[min(1, len(st.session_state.numerical_cols)-1)]: 'Value'},
                        nbins=20
                    )
                    fig.update_traces(marker_color='#667eea', marker_line_color='white', marker_line_width=1)
                    fig.update_layout(
                        title_font_size=18,
                        showlegend=False,
                        margin=dict(t=50, b=50, l=50, r=20)
                    )
                    st.plotly_chart(fig, use_container_width=True)
                
                with insights_col2:
                    # Display insights if available
                    if st.session_state.per_chart_insights.get('distribution_chart'):
                        st.markdown("""
                        <div style="background-color: #f0f8ff !important; border-left: 4px solid #667eea !important; padding: 15px !important; border-radius: 5px !important; margin-top: 20px !important;">
                            <p style="margin: 0 !important; font-size: 14px !important; font-weight: 600 !important; color: #667eea !important; margin-bottom: 10px !important;">üí° Key Insights</p>
                        """, unsafe_allow_html=True)
                        st.markdown(st.session_state.per_chart_insights['distribution_chart'])
                        st.markdown("</div>", unsafe_allow_html=True)
                    else:
                        st.info("üí° Generate Per-Chart Insights ƒë·ªÉ xem insights ri√™ng cho chart n√†y")
            
            # ‚ùπ INTERACTIVITY: Categorical breakdown with filters
            if st.session_state.categorical_cols and st.session_state.numerical_cols:
                st.markdown("---")
                st.markdown("### üé® Category Breakdown & Comparison")
                st.caption("‚ùì **Answers:** Which categories perform best/worst?")
                
                # Interactive filters
                col_filter1, col_filter2 = st.columns(2)
                with col_filter1:
                    cat_col = st.selectbox(
                        "üìä Select Category:",
                        st.session_state.categorical_cols,
                        key="overview_cat",
                        help="Choose dimension to analyze"
                    )
                with col_filter2:
                    num_col = st.selectbox(
                        "üìà Select Metric:",
                        st.session_state.numerical_cols,
                        key="overview_num",
                        help="Choose metric to measure"
                    )
                
                # Chart 3: Category Bar Chart (Bricks.ai layout: Chart | Insights)
                chart_col3, insights_col3 = st.columns([2.5, 1.5])
                
                with chart_col3:
                    # BAR CHART - For categorical comparisons (Top 10 only)
                    grouped = df.groupby(cat_col)[num_col].sum().sort_values(ascending=False).head(10)
                    
                    # ‚ù∏ DESIGN: Gradient color (best = green, worst = orange)
                    colors = ['#28A745' if i == 0 else '#0066CC' if i < 3 else '#6C757D' 
                             for i in range(len(grouped))]
                    
                    fig = px.bar(
                        x=grouped.index,
                        y=grouped.values,
                        title=f"Top 10: {num_col.replace('_', ' ').title()} by {cat_col.replace('_', ' ').title()}",
                        labels={'x': cat_col.replace('_', ' ').title(), 'y': num_col.replace('_', ' ').title()}
                    )
                    fig.update_traces(marker_color=colors, marker_line_color='white', marker_line_width=1.5)
                    fig.update_layout(
                        title_font_size=18,
                        showlegend=False,
                        margin=dict(t=50, b=80, l=50, r=20),
                        xaxis_tickangle=-45  # Readability
                    )
                    
                    # ‚ù∫ ACTIONABLE: Add annotation for top performer
                    if len(grouped) > 0:
                        max_val = grouped.max()
                        max_cat = grouped.idxmax()
                        fig.add_annotation(
                            x=max_cat,
                            y=max_val,
                            text=f"üèÜ Best: {max_cat}",
                            showarrow=True,
                            arrowhead=2,
                            arrowcolor="#28A745",
                            font=dict(size=12, color="#28A745")
                        )
                    
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # Show summary stats
                    st.caption(f"üí° **Insight:** Top performer '{grouped.idxmax()}' accounts for {(grouped.max() / grouped.sum() * 100):.1f}% of total {num_col}")
                
                with insights_col3:
                    # Display insights if available
                    if st.session_state.per_chart_insights.get('category_bar_chart'):
                        st.markdown("""
                        <div style="background-color: #f0f8ff !important; border-left: 4px solid #28A745 !important; padding: 15px !important; border-radius: 5px !important; margin-top: 20px !important;">
                            <p style="margin: 0 !important; font-size: 14px !important; font-weight: 600 !important; color: #28A745 !important; margin-bottom: 10px !important;">üí° Key Insights</p>
                        """, unsafe_allow_html=True)
                        st.markdown(st.session_state.per_chart_insights['category_bar_chart'])
                        st.markdown("</div>", unsafe_allow_html=True)
                    else:
                        st.info("üí° Generate Per-Chart Insights ƒë·ªÉ xem insights ri√™ng cho chart n√†y")
        
        with dashboard_tabs[1]:  # Detailed Analysis
            st.markdown("### üìà Detailed Analysis Dashboard")
            
            # Interactive filters
            st.markdown("#### üîç Filters")
            filter_cols = st.columns(3)
            
            active_filters = {}
            
            # Category filters
            if st.session_state.categorical_cols:
                with filter_cols[0]:
                    selected_cat = st.selectbox(
                        "Filter by Category:",
                        ['All'] + st.session_state.categorical_cols,
                        key="detail_cat_filter"
                    )
                    
                    if selected_cat != 'All':
                        cat_values = ['All'] + df[selected_cat].unique().tolist()
                        selected_val = st.selectbox(
                            f"Select {selected_cat}:",
                            cat_values,
                            key="detail_cat_val"
                        )
                        if selected_val != 'All':
                            active_filters[selected_cat] = selected_val
            
            # Apply filters
            filtered_df = df.copy()
            for col, val in active_filters.items():
                filtered_df = filtered_df[filtered_df[col] == val]
            
            st.info(f"üìä Showing {len(filtered_df)} of {len(df)} records")
            
            # Correlation heatmap (Bricks.ai layout: Chart | Insights)
            if st.session_state.numerical_cols and len(st.session_state.numerical_cols) >= 2:
                st.markdown("#### üî• Correlation Heatmap")
                
                chart_col4, insights_col4 = st.columns([2.5, 1.5])
                
                with chart_col4:
                    corr = filtered_df[st.session_state.numerical_cols].corr()
                    fig = px.imshow(
                        corr,
                        text_auto=True,
                        title="Feature Correlations",
                        color_continuous_scale="RdBu_r",
                        aspect="auto"
                    )
                    st.plotly_chart(fig, use_container_width=True)
                
                with insights_col4:
                    # Display insights if available
                    if st.session_state.per_chart_insights.get('correlation_heatmap'):
                        st.markdown("""
                        <div style="background-color: #fff5f5 !important; border-left: 4px solid #DC3545 !important; padding: 15px !important; border-radius: 5px !important; margin-top: 20px !important;">
                            <p style="margin: 0 !important; font-size: 14px !important; font-weight: 600 !important; color: #DC3545 !important; margin-bottom: 10px !important;">üí° Key Insights</p>
                        """, unsafe_allow_html=True)
                        st.markdown(st.session_state.per_chart_insights['correlation_heatmap'])
                        st.markdown("</div>", unsafe_allow_html=True)
                    else:
                        st.info("üí° Generate Per-Chart Insights ƒë·ªÉ xem insights ri√™ng cho chart n√†y")
            
            # Scatter matrix for multi-variate analysis
            if len(st.session_state.numerical_cols) >= 2:
                st.markdown("#### üéØ Multi-Variate Analysis")
                selected_cols = st.multiselect(
                    "Select columns for scatter matrix:",
                    st.session_state.numerical_cols,
                    default=st.session_state.numerical_cols[:min(3, len(st.session_state.numerical_cols))],
                    key="scatter_matrix_cols"
                )
                
                if len(selected_cols) >= 2:
                    fig = px.scatter_matrix(
                        filtered_df[selected_cols],
                        title="Scatter Matrix",
                        height=600
                    )
                    st.plotly_chart(fig, use_container_width=True)
        
        with dashboard_tabs[2]:  # KPIs & Metrics
            st.markdown("### üéØ KPIs & Metrics Dashboard")
            st.markdown("*D·ª±a tr√™n OQMLB Metrics Section*")
            
            # Show all numerical metrics
            if st.session_state.numerical_cols:
                st.markdown("#### üìä All Metrics Summary")
                
                metrics_data = []
                for col in st.session_state.numerical_cols:
                    metrics_data.append({
                        'Metric': col.replace('_', ' ').title(),
                        'Mean': f"{df[col].mean():.2f}",
                        'Median': f"{df[col].median():.2f}",
                        'Std Dev': f"{df[col].std():.2f}",
                        'Min': f"{df[col].min():.2f}",
                        'Max': f"{df[col].max():.2f}"
                    })
                
                metrics_df = pd.DataFrame(metrics_data)
                st.dataframe(metrics_df, use_container_width=True, hide_index=True)
                
                st.markdown("---")
                
                # Individual metric deep dive
                st.markdown("#### üîé Metric Deep Dive")
                selected_metric = st.selectbox(
                    "Select metric to analyze:",
                    st.session_state.numerical_cols,
                    key="metric_deepdive"
                )
                
                if selected_metric:
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        # Box plot
                        metric_label = selected_metric.replace('_', ' ').title()
                        fig = px.box(
                            df,
                            y=selected_metric,
                            title=f"{selected_metric} - Box Plot",
                            labels={selected_metric: metric_label}
                        )
                        st.plotly_chart(fig, use_container_width=True)
                    
                    with col2:
                        # Violin plot
                        metric_label = selected_metric.replace('_', ' ').title()
                        fig = px.violin(
                            df,
                            y=selected_metric,
                            title=f"{selected_metric} - Distribution",
                            labels={selected_metric: metric_label}
                        )
                        st.plotly_chart(fig, use_container_width=True)
        
        with dashboard_tabs[3]:  # Export & Code
            st.markdown("### üì• Export Dashboard & Code")
            
            st.success("‚úÖ Dashboard ƒë√£ s·∫µn s√†ng ƒë·ªÉ export!")
            
            # Generate Executive Summary first (if not already generated)
            client = init_gemini()
            if client and not st.session_state.executive_summary:
                if st.button("üéØ Generate Executive Summary (AI-Powered)", type="primary", use_container_width=True):
                    with st.spinner("ü§ñ AI ƒëang t·∫°o Executive Summary chuy√™n nghi·ªáp..."):
                        success, summary = generate_executive_summary(
                            client, 
                            df, 
                            st.session_state.dashboard_blueprint or "", 
                            st.session_state.analysis_goal or ""
                        )
                        if success:
                            st.session_state.executive_summary = summary
                            st.rerun()
                        else:
                            st.error(f"‚ùå L·ªói: {summary}")
            
            # Show Executive Summary if available
            if st.session_state.executive_summary:
                with st.expander("üìä Executive Summary Preview", expanded=False):
                    st.markdown(st.session_state.executive_summary)
                st.success("‚úÖ Executive Summary s·∫µn s√†ng cho PDF/PowerPoint export!")
            else:
                st.info("üí° Click n√∫t 'Generate Executive Summary' ƒë·ªÉ t·∫°o b√°o c√°o 1-page cho CEO/CFO")
            
            st.markdown("---")
            st.markdown("### üìÑ Professional Reports (NEW!)")
            
            # PDF + PowerPoint Export (Row 1)
            report_col1, report_col2 = st.columns(2)
            
            with report_col1:
                st.markdown("#### üìÑ PDF Report")
                st.caption("Professional multi-page report v·ªõi Executive Summary, KPIs, Blueprint")
                
                if st.button("üì• Generate & Download PDF Report", use_container_width=True):
                    with st.spinner("üìÑ Generating PDF..."):
                        try:
                            pdf_bytes = generate_pdf_report(
                                df,
                                st.session_state.executive_summary or "Executive Summary not generated yet.",
                                st.session_state.dashboard_blueprint or "",
                                st.session_state.analysis_goal or ""
                            )
                            st.download_button(
                                "‚¨áÔ∏è Download PDF Report",
                                data=pdf_bytes,
                                file_name=f"analytics_report_{datetime.now().strftime('%Y%m%d_%H%M')}.pdf",
                                mime="application/pdf",
                                use_container_width=True
                            )
                            st.success("‚úÖ PDF Report generated successfully!")
                        except Exception as e:
                            st.error(f"‚ùå Error generating PDF: {str(e)}")
                
                if not st.session_state.executive_summary:
                    st.warning("‚ö†Ô∏è Generate Executive Summary first for best results!")
            
            with report_col2:
                st.markdown("#### üìä PowerPoint Presentation")
                st.caption("8-slide presentation ready cho Board meetings")
                
                if st.button("üì• Generate & Download PowerPoint", use_container_width=True):
                    with st.spinner("üìä Generating PowerPoint..."):
                        try:
                            ppt_bytes = generate_powerpoint_report(
                                df,
                                st.session_state.executive_summary or "Executive Summary not generated yet.",
                                st.session_state.dashboard_blueprint or "",
                                st.session_state.analysis_goal or ""
                            )
                            st.download_button(
                                "‚¨áÔ∏è Download PowerPoint",
                                data=ppt_bytes,
                                file_name=f"analytics_presentation_{datetime.now().strftime('%Y%m%d_%H%M')}.pptx",
                                mime="application/vnd.openxmlformats-officedocument.presentationml.presentation",
                                use_container_width=True
                            )
                            st.success("‚úÖ PowerPoint generated successfully!")
                        except Exception as e:
                            st.error(f"‚ùå Error generating PowerPoint: {str(e)}")
                
                if not st.session_state.executive_summary:
                    st.warning("‚ö†Ô∏è Generate Executive Summary first for best results!")
            
            st.markdown("---")
            st.markdown("### üì¶ Data & Code Exports")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.markdown("#### üìä Data Export")
                # Export cleaned data
                csv = df.to_csv(index=False).encode('utf-8')
                st.download_button(
                    "‚¨áÔ∏è Download Cleaned Data (CSV)",
                    data=csv,
                    file_name=f"cleaned_data_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                    mime="text/csv",
                    use_container_width=True
                )
                
                # Export to Excel
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                    df.to_excel(writer, sheet_name='Data', index=False)
                excel_data = output.getvalue()
                
                st.download_button(
                    "‚¨áÔ∏è Download Cleaned Data (Excel)",
                    data=excel_data,
                    file_name=f"cleaned_data_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True
                )
            
            with col2:
                st.markdown("#### üìã Blueprint Export")
                if st.session_state.dashboard_blueprint:
                    st.download_button(
                        "‚¨áÔ∏è Download Blueprint (Markdown)",
                        data=st.session_state.dashboard_blueprint,
                        file_name=f"dashboard_blueprint_{datetime.now().strftime('%Y%m%d_%H%M')}.md",
                        mime="text/markdown",
                        use_container_width=True
                    )
                    
                    st.download_button(
                        "‚¨áÔ∏è Download Blueprint (Text)",
                        data=st.session_state.dashboard_blueprint,
                        file_name=f"dashboard_blueprint_{datetime.now().strftime('%Y%m%d_%H%M')}.txt",
                        mime="text/plain",
                        use_container_width=True
                    )
            
            with col3:
                st.markdown("#### üêç Code Export")
                
                # Generate sample dashboard code
                dashboard_code = f"""# Auto-Generated Dashboard Code
# Generated from DataAnalytics Vietnam
# Date: {datetime.now().strftime('%Y-%m-%d %H:%M')}

import streamlit as st
import pandas as pd
import plotly.express as px

# Load data
df = pd.read_csv('cleaned_data.csv')

# Dashboard Title
st.title('üìä Auto-Generated Dashboard')

# KPIs
st.markdown('## üéØ Key Metrics')
cols = st.columns(4)

numerical_cols = {st.session_state.numerical_cols}

for i, col in enumerate(numerical_cols[:4]):
    with cols[i]:
        st.metric(
            label=col,
            value=f"{{df[col].mean():.2f}}"
        )

# Visualizations
st.markdown('## üìà Visualizations')

# Trend chart
fig = px.line(df, y=numerical_cols[0])
st.plotly_chart(fig, use_container_width=True)

# Distribution
fig = px.histogram(df, x=numerical_cols[1] if len(numerical_cols) > 1 else numerical_cols[0])
st.plotly_chart(fig, use_container_width=True)
"""
                
                st.download_button(
                    "‚¨áÔ∏è Download Dashboard Code (.py)",
                    data=dashboard_code,
                    file_name=f"dashboard_code_{datetime.now().strftime('%Y%m%d_%H%M')}.py",
                    mime="text/x-python",
                    use_container_width=True
                )
                
                st.info("üí° Code n√†y c√≥ th·ªÉ ch·∫°y ƒë·ªôc l·∫≠p v·ªõi Streamlit!")
            
            st.markdown("---")
            st.markdown("### üéØ PHASE 1B: Dashboard Templates (Reusable Layouts)")
            st.caption("*Save dashboard configuration ƒë·ªÉ reuse v·ªõi data m·ªõi - gi·ªëng Bricks.ai template system!*")
            
            template_col1, template_col2 = st.columns(2)
            
            with template_col1:
                st.markdown("#### üíæ Save Template")
                st.write("L∆∞u c·∫•u h√¨nh dashboard n√†y (blueprint + column mappings) ƒë·ªÉ reuse sau")
                
                if st.session_state.blueprint_structured_data:
                    try:
                        template_json = save_dashboard_template(
                            st.session_state.blueprint_structured_data,
                            st.session_state.analysis_goal,
                            st.session_state.categorical_cols,
                            st.session_state.numerical_cols,
                            st.session_state.date_cols
                        )
                        
                        st.download_button(
                            "üì• Download Dashboard Template",
                            data=template_json,
                            file_name=f"dashboard_template_{datetime.now().strftime('%Y%m%d_%H%M')}.json",
                            mime="application/json",
                            use_container_width=True,
                            type="primary",
                            key="download_template_direct"
                        )
                        
                        st.success("‚úÖ Click button above ƒë·ªÉ download template JSON!")
                    except Exception as e:
                        st.error(f"‚ùå Error generating template: {str(e)}")
                else:
                    st.warning("‚ö†Ô∏è No blueprint data available - generate blueprint first in Step 4!")
                
                st.info("üí° Template bao g·ªìm: Blueprint OQMLB + Column types + Analysis goals")
            
            with template_col2:
                st.markdown("#### üìÇ Load Template")
                st.write("Upload template ƒë·ªÉ apply l√™n new dataset (same structure)")
                
                uploaded_template = st.file_uploader(
                    "Upload Dashboard Template (JSON)",
                    type=['json'],
                    key="template_uploader",
                    help="Upload template JSON file ƒë√£ save tr∆∞·ªõc ƒë√≥"
                )
                
                if uploaded_template:
                    try:
                        template_content = uploaded_template.read().decode('utf-8')
                        success, template_data = load_dashboard_template(template_content)
                        
                        if success:
                            st.success("‚úÖ Template loaded successfully!")
                            
                            with st.expander("üìã Template Preview", expanded=False):
                                st.json({
                                    "created_at": template_data.get('created_at'),
                                    "analysis_goal": template_data.get('analysis_goal'),
                                    "categorical_cols": template_data.get('column_types', {}).get('categorical', []),
                                    "numerical_cols": template_data.get('column_types', {}).get('numerical', [])
                                })
                            
                            if st.button("‚ú® Apply Template to Current Data", use_container_width=True):
                                # Apply template to current dataset
                                st.session_state.dashboard_template = template_data
                                st.session_state.analysis_goal = template_data.get('analysis_goal', '')
                                st.session_state.blueprint_structured_data = template_data.get('blueprint', {})
                                st.success("üéâ Template applied! Dashboard rebuilt v·ªõi template layout")
                                st.rerun()
                        else:
                            st.error(f"‚ùå Error loading template: {template_data.get('error', 'Unknown error')}")
                    except Exception as e:
                        st.error(f"‚ùå Error reading template: {str(e)}")
                
                st.info("üí° Template matching: Upload data v·ªõi c√πng column structure")
            
            st.markdown("---")
            st.markdown("### üé® Next Steps")
            
            st.markdown("""
            **Dashboard c·ªßa b·∫°n ƒë√£ s·∫µn s√†ng!** üéâ
            
            B·∫°n c√≥ th·ªÉ:
            1. ‚úÖ **Export data** ƒë·ªÉ s·ª≠ d·ª•ng trong tools kh√°c (Excel, PowerBI, Tableau)
            2. ‚úÖ **Download blueprint** ƒë·ªÉ tham kh·∫£o thi·∫øt k·∫ø chi ti·∫øt
            3. ‚úÖ **Download Python code** ƒë·ªÉ customize v√† deploy ƒë·ªôc l·∫≠p
            4. ‚úÖ **Share dashboard** n√†y v·ªõi team b·∫±ng c√°ch publish app
            
            **üí° Pro Tips:**
            - Blueprint ch·ª©a ƒë·∫ßy ƒë·ªß OQMLB framework ƒë·ªÉ b·∫°n build tr√™n b·∫•t k·ª≥ platform n√†o
            - Python code c√≥ th·ªÉ customize th√™m filters, charts, v√† features
            - Cleaned data ƒë√£ ƒë∆∞·ª£c optimize v√† s·∫µn s√†ng cho analysis
            """)

# Footer
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666; padding: 2rem;'>
    <p><strong>DataAnalytics Vietnam</strong> - Powered by Gemini AI</p>
    <p>Built with ‚ù§Ô∏è for Vietnamese SMEs</p>
</div>
""", unsafe_allow_html=True)
